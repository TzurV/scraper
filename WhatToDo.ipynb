{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by importing the main PyTorch package along with the *Variable* class used to store our data tensors and the *nn* package which we will use when building the model. In addition, we'll only be using numpy to pre-process our data as Torch works really well with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1, 2, 3, 4])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n",
      "   y_Actual  y_Predicted\n",
      "0         1            1\n",
      "1         0            1\n",
      "2         0            0\n",
      "3         1            1\n",
      "4         0            0\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          5  2\n",
      "1          1  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaeb\" ><thead>    <tr>        <th class=\"index_name level0\" >Predicted</th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>    </tr>    <tr>        <th class=\"index_name level0\" >Actual</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaeblevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow0_col0\" class=\"data row0 col0\" >5</td>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow0_col1\" class=\"data row0 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaeblevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow1_col1\" class=\"data row1 col1\" >4</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17328a9fa08>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://datatofish.com/confusion-matrix-python/\n",
    "\n",
    "import pandas as pd\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "\n",
    "data = {'y_Actual':    [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
    "        'y_Predicted': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
    "        }\n",
    "\n",
    "print(len(data['y_Actual']), len(data['y_Predicted']))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print(df.head())\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "confusion_matrix.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/get-started/locally/#mac-anaconda\n",
    "# conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dammy train test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create to typ of x^3 data sets predicting the next 2 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23309093 0.45164794 0.05867559 0.48031216]\n",
      "[ 0.46153371 -0.15806776 -0.22464431  3.21391268]\n",
      "[ 1.98233027  0.42121132 -1.81317508 -2.03645184]\n",
      "[-0.79195265 -0.70955964 -2.82003918  0.28133835]\n",
      "[[ 0.          0.1         0.3         0.5       ]\n",
      " [ 0.5        -0.2        -0.2         3.        ]\n",
      " [ 2.          0.3        -1.5        -2.        ]\n",
      " ...\n",
      " [ 0.37721847 -0.19278121  0.08896957  2.58344273]\n",
      " [ 2.04513343  0.19070594 -1.10348105 -2.29168139]\n",
      " [-0.64605173 -0.40244924 -2.68544393  0.20519928]]\n",
      "[1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "import glob, os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def func(x, a, b, c, d):\n",
    "    ''' ~x^3 curve     '''\n",
    "    return a + b * x + c * x * x + d * pow(x,3)\n",
    "\n",
    "\n",
    "Pos = [ [0, 0.1 , 0.3, 0.5],\n",
    "        [0.5, -0.2 , -0.2, 3],\n",
    "       [2, 0.3, -1.5, -2],\n",
    "       [-0.5, -0.7, -3, 0.1]]\n",
    "\n",
    "out = [1 ,1 , 0 , 0]\n",
    "   \n",
    "npPos = np.array(Pos)\n",
    "npOut = np.array(out)\n",
    "\n",
    "noise = np.random.normal(size=(4,4)) / 5\n",
    "npPos1 = npPos+noise\n",
    "\n",
    "#https://matplotlib.org/gallery/subplots_axes_and_figures/demo_constrained_layout.html#sphx-glr-gallery-subplots-axes-and-figures-demo-constrained-layout-py\n",
    "fig1, f1_axes = plt.subplots(ncols=2, nrows=2, constrained_layout=True)\n",
    "xData = np.linspace(-5, 5, 20)\n",
    "for V, ax in zip(npPos1, f1_axes.flat):\n",
    "    print(V)\n",
    "    yData = func(xData, *V)\n",
    "    ax.plot(xData, yData)\n",
    "    #ax.set_xlabel(str(V))\n",
    "fig1.show()\n",
    "\n",
    "\n",
    "XtrainData = npPos\n",
    "YtrainData = npOut\n",
    "for ii in range(100):\n",
    "    noise = np.random.normal(size=(4,4)) / 5\n",
    "    npPos1 = npPos+noise\n",
    "    XtrainData = np.concatenate((XtrainData, npPos1), axis=0)\n",
    "    YtrainData = np.concatenate((YtrainData, npOut ), axis=0)\n",
    "    \n",
    "print(XtrainData)\n",
    "print(YtrainData)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllCells = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're going to predict the next character in the sequence at each time step, we'll have to divide each sentence into\n",
    "\n",
    "- Input data\n",
    "    - The last input character should be excluded as it does not need to be fed into the model\n",
    "- Target/Ground Truth Label\n",
    "    - One time-step ahead of the Input data as this will be the \"correct answer\" for the model at each time step corresponding to the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're done with all the data pre-processing, we can now move the data from numpy arrays to PyTorch's very own data structure - **Torch Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.from_numpy(XtrainData)\n",
    "target_seq = torch.Tensor(YtrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4]) 16\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(input_seq.shape, input_seq.shape[0])\n",
    "print(target_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've reached the fun part of this project! We'll be defining the model using the Torch library, and this is where you can add or remove layers, be it fully connected layers, convolutational layers, vanilla RNN layers, LSTM layers, and many more! In this post, we'll be using the basic nn.rnn to demonstrate a simple example of how RNNs can be used.\n",
    "\n",
    "Before we start building the model, let's use a build in feature in PyTorch to check the device we're running on (CPU or GPU). This implementation will not require GPU as the training is really simple. However, as you progress on to large datasets and models with millions of trainable parameters, using the GPU will be very important to speed up your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 11:46:44.008501\n"
     ]
    }
   ],
   "source": [
    "dateNow = datetime.datetime.now()\n",
    "print(dateNow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 10, 10, 1\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([404, 4]) torch.Size([404, 1])\n"
     ]
    }
   ],
   "source": [
    "# change numpy representation to float and conver to pytorch tensor\n",
    "x = torch.from_numpy(XtrainData.astype(np.float32))\n",
    "y = torch.from_numpy(YtrainData.astype(np.float32))\n",
    "# add a Dimension\n",
    "y = y.unsqueeze(1)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = x.shape[0], 4, 4, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim torch.Size([404, 4])\n",
      "Input tensor([0.0000, 0.1000, 0.3000, 0.5000], device='cuda:0') -> output tensor([1.], device='cuda:0')\n",
      "TwoLayerNet(\n",
      "  (linear1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "Num Model Parameters  25\n",
      "99 4.782670497894287\n",
      "299 1.8459484577178955\n",
      "499 1.6288139820098877\n",
      "699 1.5125527381896973\n",
      "899 1.436309576034546\n",
      "Hyp 0.9891024827957153 : Real Out 1.0\n",
      "Hyp 1.00047767162323 : Real Out 1.0\n",
      "Hyp -0.0007028281688690186 : Real Out 0.0\n",
      "Hyp -0.010086268186569214 : Real Out 0.0\n",
      "Hyp 1.0226119756698608 : Real Out 1.0\n",
      "Hyp 1.002943515777588 : Real Out 1.0\n",
      "Hyp 0.12553495168685913 : Real Out 0.0\n",
      "Hyp 0.09721928834915161 : Real Out 0.0\n",
      "Hyp 1.0206334590911865 : Real Out 1.0\n",
      "Hyp 1.0409222841262817 : Real Out 1.0\n",
      "Hyp -0.020735979080200195 : Real Out 0.0\n",
      "Hyp 0.09039703011512756 : Real Out 0.0\n",
      "Hyp 0.9545400142669678 : Real Out 1.0\n",
      "Hyp 1.0015513896942139 : Real Out 1.0\n",
      "Hyp -0.06005096435546875 : Real Out 0.0\n",
      "Hyp -0.10011947154998779 : Real Out 0.0\n",
      "Hyp 0.9601424336433411 : Real Out 1.0\n",
      "Hyp 1.02988600730896 : Real Out 1.0\n",
      "Hyp 0.04720979928970337 : Real Out 0.0\n",
      "Hyp 0.04179009795188904 : Real Out 0.0\n",
      "Hyp 1.0362746715545654 : Real Out 1.0\n",
      "Hyp 1.005760669708252 : Real Out 1.0\n",
      "Hyp -0.0396842360496521 : Real Out 0.0\n",
      "Hyp 0.010881543159484863 : Real Out 0.0\n",
      "Hyp 0.9809496402740479 : Real Out 1.0\n",
      "Hyp 0.9948400855064392 : Real Out 1.0\n",
      "Hyp -0.03953230381011963 : Real Out 0.0\n",
      "Hyp -0.104148268699646 : Real Out 0.0\n",
      "Hyp 0.9805105328559875 : Real Out 1.0\n",
      "Hyp 1.041238784790039 : Real Out 1.0\n",
      "Hyp 0.10716885328292847 : Real Out 0.0\n",
      "Hyp -0.025076866149902344 : Real Out 0.0\n",
      "Hyp 0.9560853242874146 : Real Out 1.0\n",
      "Hyp 1.001015067100525 : Real Out 1.0\n",
      "Hyp 0.06817567348480225 : Real Out 0.0\n",
      "Hyp 0.023878365755081177 : Real Out 0.0\n",
      "Hyp 1.0382615327835083 : Real Out 1.0\n",
      "Hyp 0.9786962866783142 : Real Out 1.0\n",
      "Hyp 0.012393057346343994 : Real Out 0.0\n",
      "Hyp 0.02403220534324646 : Real Out 0.0\n",
      "Hyp 1.0621559619903564 : Real Out 1.0\n",
      "Hyp 0.9765599966049194 : Real Out 1.0\n",
      "Hyp -0.09139567613601685 : Real Out 0.0\n",
      "Hyp -0.03604447841644287 : Real Out 0.0\n",
      "Hyp 1.0227186679840088 : Real Out 1.0\n",
      "Hyp 0.9164775013923645 : Real Out 1.0\n",
      "Hyp 0.17827773094177246 : Real Out 0.0\n",
      "Hyp -0.05699437856674194 : Real Out 0.0\n",
      "Hyp 0.9777463674545288 : Real Out 1.0\n",
      "Hyp 0.9509890079498291 : Real Out 1.0\n",
      "Hyp -0.001553177833557129 : Real Out 0.0\n",
      "Hyp -0.01597970724105835 : Real Out 0.0\n",
      "Hyp 0.9913527369499207 : Real Out 1.0\n",
      "Hyp 0.938667893409729 : Real Out 1.0\n",
      "Hyp -0.12756454944610596 : Real Out 0.0\n",
      "Hyp 0.04462519288063049 : Real Out 0.0\n",
      "Hyp 0.9396668672561646 : Real Out 1.0\n",
      "Hyp 1.020843505859375 : Real Out 1.0\n",
      "Hyp -0.0493091344833374 : Real Out 0.0\n",
      "Hyp -0.05040252208709717 : Real Out 0.0\n",
      "Hyp 0.9602482318878174 : Real Out 1.0\n",
      "Hyp 1.0202817916870117 : Real Out 1.0\n",
      "Hyp 0.04052382707595825 : Real Out 0.0\n",
      "Hyp 0.04851812124252319 : Real Out 0.0\n",
      "Hyp 1.0280256271362305 : Real Out 1.0\n",
      "Hyp 0.9938364624977112 : Real Out 1.0\n",
      "Hyp 0.05718502402305603 : Real Out 0.0\n",
      "Hyp -0.08821016550064087 : Real Out 0.0\n",
      "Hyp 1.0042113065719604 : Real Out 1.0\n",
      "Hyp 1.1188044548034668 : Real Out 1.0\n",
      "Hyp -0.022888779640197754 : Real Out 0.0\n",
      "Hyp 0.026693761348724365 : Real Out 0.0\n",
      "Hyp 1.0024354457855225 : Real Out 1.0\n",
      "Hyp 1.0187313556671143 : Real Out 1.0\n",
      "Hyp -0.11393868923187256 : Real Out 0.0\n",
      "Hyp -0.08922380208969116 : Real Out 0.0\n",
      "Hyp 0.9609235525131226 : Real Out 1.0\n",
      "Hyp 0.9693389534950256 : Real Out 1.0\n",
      "Hyp -0.024939358234405518 : Real Out 0.0\n",
      "Hyp -0.0508577823638916 : Real Out 0.0\n",
      "Hyp 0.9292824268341064 : Real Out 1.0\n",
      "Hyp 1.0309053659439087 : Real Out 1.0\n",
      "Hyp -0.0646410584449768 : Real Out 0.0\n",
      "Hyp 0.021265387535095215 : Real Out 0.0\n",
      "Hyp 0.9310618042945862 : Real Out 1.0\n",
      "Hyp 1.0287392139434814 : Real Out 1.0\n",
      "Hyp 0.03143593668937683 : Real Out 0.0\n",
      "Hyp 0.0697905421257019 : Real Out 0.0\n",
      "Hyp 0.9602126479148865 : Real Out 1.0\n",
      "Hyp 1.0110950469970703 : Real Out 1.0\n",
      "Hyp 0.043756306171417236 : Real Out 0.0\n",
      "Hyp 0.034473925828933716 : Real Out 0.0\n",
      "Hyp 0.9928557872772217 : Real Out 1.0\n",
      "Hyp 0.9828548431396484 : Real Out 1.0\n",
      "Hyp -0.2091938853263855 : Real Out 0.0\n",
      "Hyp 0.03719666600227356 : Real Out 0.0\n",
      "Hyp 0.9597084522247314 : Real Out 1.0\n",
      "Hyp 0.9762426614761353 : Real Out 1.0\n",
      "Hyp 0.003657221794128418 : Real Out 0.0\n",
      "Hyp -0.06272530555725098 : Real Out 0.0\n",
      "Hyp 0.9375914931297302 : Real Out 1.0\n",
      "Hyp 0.9871834516525269 : Real Out 1.0\n",
      "Hyp -0.03942996263504028 : Real Out 0.0\n",
      "Hyp -0.026820659637451172 : Real Out 0.0\n",
      "Hyp 0.9645769596099854 : Real Out 1.0\n",
      "Hyp 0.9818326830863953 : Real Out 1.0\n",
      "Hyp -0.033428072929382324 : Real Out 0.0\n",
      "Hyp 0.07117626070976257 : Real Out 0.0\n",
      "Hyp 1.0303574800491333 : Real Out 1.0\n",
      "Hyp 0.9564942121505737 : Real Out 1.0\n",
      "Hyp -0.035018086433410645 : Real Out 0.0\n",
      "Hyp 0.020153582096099854 : Real Out 0.0\n",
      "Hyp 1.0123950242996216 : Real Out 1.0\n",
      "Hyp 1.0810216665267944 : Real Out 1.0\n",
      "Hyp -0.09752672910690308 : Real Out 0.0\n",
      "Hyp 0.15609478950500488 : Real Out 0.0\n",
      "Hyp 0.9418506026268005 : Real Out 1.0\n",
      "Hyp 0.9796069860458374 : Real Out 1.0\n",
      "Hyp 0.031856030225753784 : Real Out 0.0\n",
      "Hyp -0.08099347352981567 : Real Out 0.0\n",
      "Hyp 1.0637638568878174 : Real Out 1.0\n",
      "Hyp 1.0553624629974365 : Real Out 1.0\n",
      "Hyp -0.05571681261062622 : Real Out 0.0\n",
      "Hyp 0.0025051534175872803 : Real Out 0.0\n",
      "Hyp 0.9924722909927368 : Real Out 1.0\n",
      "Hyp 0.9632226824760437 : Real Out 1.0\n",
      "Hyp 0.09858614206314087 : Real Out 0.0\n",
      "Hyp -0.017095446586608887 : Real Out 0.0\n",
      "Hyp 0.9709599018096924 : Real Out 1.0\n",
      "Hyp 1.0206868648529053 : Real Out 1.0\n",
      "Hyp 0.03546115756034851 : Real Out 0.0\n",
      "Hyp -0.08187240362167358 : Real Out 0.0\n",
      "Hyp 1.0018084049224854 : Real Out 1.0\n",
      "Hyp 1.0021989345550537 : Real Out 1.0\n",
      "Hyp -0.0840577483177185 : Real Out 0.0\n",
      "Hyp 0.0243566632270813 : Real Out 0.0\n",
      "Hyp 0.9946551322937012 : Real Out 1.0\n",
      "Hyp 1.0819172859191895 : Real Out 1.0\n",
      "Hyp -0.09343057870864868 : Real Out 0.0\n",
      "Hyp -0.043499529361724854 : Real Out 0.0\n",
      "Hyp 0.9784964323043823 : Real Out 1.0\n",
      "Hyp 1.0735682249069214 : Real Out 1.0\n",
      "Hyp -0.014839231967926025 : Real Out 0.0\n",
      "Hyp -0.07046067714691162 : Real Out 0.0\n",
      "Hyp 1.0548160076141357 : Real Out 1.0\n",
      "Hyp 0.9123762845993042 : Real Out 1.0\n",
      "Hyp -0.053234100341796875 : Real Out 0.0\n",
      "Hyp -0.05415922403335571 : Real Out 0.0\n",
      "Hyp 0.9850481748580933 : Real Out 1.0\n",
      "Hyp 1.0105820894241333 : Real Out 1.0\n",
      "Hyp 0.03985300660133362 : Real Out 0.0\n",
      "Hyp 0.03327372670173645 : Real Out 0.0\n",
      "Hyp 1.00931715965271 : Real Out 1.0\n",
      "Hyp 1.0238118171691895 : Real Out 1.0\n",
      "Hyp -0.006851077079772949 : Real Out 0.0\n",
      "Hyp 0.038719743490219116 : Real Out 0.0\n",
      "Hyp 1.0076053142547607 : Real Out 1.0\n",
      "Hyp 1.0185086727142334 : Real Out 1.0\n",
      "Hyp 0.12320977449417114 : Real Out 0.0\n",
      "Hyp 0.04777058959007263 : Real Out 0.0\n",
      "Hyp 1.0557557344436646 : Real Out 1.0\n",
      "Hyp 0.9696054458618164 : Real Out 1.0\n",
      "Hyp -0.08026009798049927 : Real Out 0.0\n",
      "Hyp -0.04683887958526611 : Real Out 0.0\n",
      "Hyp 0.9732257723808289 : Real Out 1.0\n",
      "Hyp 1.0021549463272095 : Real Out 1.0\n",
      "Hyp -0.018576085567474365 : Real Out 0.0\n",
      "Hyp -0.04409170150756836 : Real Out 0.0\n",
      "Hyp 0.9905936121940613 : Real Out 1.0\n",
      "Hyp 1.0155203342437744 : Real Out 1.0\n",
      "Hyp 0.1087278425693512 : Real Out 0.0\n",
      "Hyp -0.0026320815086364746 : Real Out 0.0\n",
      "Hyp 1.0096832513809204 : Real Out 1.0\n",
      "Hyp 1.0137605667114258 : Real Out 1.0\n",
      "Hyp 0.08596211671829224 : Real Out 0.0\n",
      "Hyp 0.005073815584182739 : Real Out 0.0\n",
      "Hyp 0.9580041170120239 : Real Out 1.0\n",
      "Hyp 1.0002710819244385 : Real Out 1.0\n",
      "Hyp -0.07371360063552856 : Real Out 0.0\n",
      "Hyp 0.06404316425323486 : Real Out 0.0\n",
      "Hyp 0.9963805079460144 : Real Out 1.0\n",
      "Hyp 0.9270529747009277 : Real Out 1.0\n",
      "Hyp 0.07909739017486572 : Real Out 0.0\n",
      "Hyp -0.057630836963653564 : Real Out 0.0\n",
      "Hyp 0.883694052696228 : Real Out 1.0\n",
      "Hyp 0.9144610166549683 : Real Out 1.0\n",
      "Hyp -0.1350274682044983 : Real Out 0.0\n",
      "Hyp 0.03079146146774292 : Real Out 0.0\n",
      "Hyp 0.9780148267745972 : Real Out 1.0\n",
      "Hyp 1.0428690910339355 : Real Out 1.0\n",
      "Hyp -0.07048356533050537 : Real Out 0.0\n",
      "Hyp 0.10818004608154297 : Real Out 0.0\n",
      "Hyp 1.0017178058624268 : Real Out 1.0\n",
      "Hyp 1.0189988613128662 : Real Out 1.0\n",
      "Hyp -0.09532004594802856 : Real Out 0.0\n",
      "Hyp 0.09150442481040955 : Real Out 0.0\n",
      "Hyp 0.967189371585846 : Real Out 1.0\n",
      "Hyp 1.002813696861267 : Real Out 1.0\n",
      "Hyp 0.19442930817604065 : Real Out 0.0\n",
      "Hyp -0.1366228461265564 : Real Out 0.0\n",
      "Hyp 0.9516686201095581 : Real Out 1.0\n",
      "Hyp 1.018449306488037 : Real Out 1.0\n",
      "Hyp 0.11302563548088074 : Real Out 0.0\n",
      "Hyp 0.027042686939239502 : Real Out 0.0\n",
      "Hyp 1.016971230506897 : Real Out 1.0\n",
      "Hyp 0.9657336473464966 : Real Out 1.0\n",
      "Hyp -0.05704444646835327 : Real Out 0.0\n",
      "Hyp -0.04807615280151367 : Real Out 0.0\n",
      "Hyp 1.0585590600967407 : Real Out 1.0\n",
      "Hyp 1.0331048965454102 : Real Out 1.0\n",
      "Hyp 0.15723711252212524 : Real Out 0.0\n",
      "Hyp 0.028320610523223877 : Real Out 0.0\n",
      "Hyp 0.9959417581558228 : Real Out 1.0\n",
      "Hyp 1.0182926654815674 : Real Out 1.0\n",
      "Hyp 0.0546286404132843 : Real Out 0.0\n",
      "Hyp 0.013076603412628174 : Real Out 0.0\n",
      "Hyp 0.9782570004463196 : Real Out 1.0\n",
      "Hyp 1.0159423351287842 : Real Out 1.0\n",
      "Hyp -0.04908102750778198 : Real Out 0.0\n",
      "Hyp -0.056373655796051025 : Real Out 0.0\n",
      "Hyp 1.0059106349945068 : Real Out 1.0\n",
      "Hyp 1.0391290187835693 : Real Out 1.0\n",
      "Hyp -0.0904771089553833 : Real Out 0.0\n",
      "Hyp -0.06517505645751953 : Real Out 0.0\n",
      "Hyp 1.0614272356033325 : Real Out 1.0\n",
      "Hyp 0.9406623840332031 : Real Out 1.0\n",
      "Hyp 0.04224121570587158 : Real Out 0.0\n",
      "Hyp -0.046600341796875 : Real Out 0.0\n",
      "Hyp 1.003951072692871 : Real Out 1.0\n",
      "Hyp 1.0043065547943115 : Real Out 1.0\n",
      "Hyp 0.1135249137878418 : Real Out 0.0\n",
      "Hyp -0.06899517774581909 : Real Out 0.0\n",
      "Hyp 0.9992838501930237 : Real Out 1.0\n",
      "Hyp 1.01884126663208 : Real Out 1.0\n",
      "Hyp 0.02508530020713806 : Real Out 0.0\n",
      "Hyp 0.02283656597137451 : Real Out 0.0\n",
      "Hyp 1.0018010139465332 : Real Out 1.0\n",
      "Hyp 1.0661506652832031 : Real Out 1.0\n",
      "Hyp 0.03789949417114258 : Real Out 0.0\n",
      "Hyp 0.05025947093963623 : Real Out 0.0\n",
      "Hyp 0.9713672995567322 : Real Out 1.0\n",
      "Hyp 1.0048158168792725 : Real Out 1.0\n",
      "Hyp -0.09082591533660889 : Real Out 0.0\n",
      "Hyp -0.01547783613204956 : Real Out 0.0\n",
      "Hyp 1.0391197204589844 : Real Out 1.0\n",
      "Hyp 1.0019536018371582 : Real Out 1.0\n",
      "Hyp -0.04506254196166992 : Real Out 0.0\n",
      "Hyp -0.02091658115386963 : Real Out 0.0\n",
      "Hyp 0.9577733278274536 : Real Out 1.0\n",
      "Hyp 1.0083832740783691 : Real Out 1.0\n",
      "Hyp 0.08018237352371216 : Real Out 0.0\n",
      "Hyp -0.001528918743133545 : Real Out 0.0\n",
      "Hyp 0.989668071269989 : Real Out 1.0\n",
      "Hyp 0.9582331776618958 : Real Out 1.0\n",
      "Hyp -0.08372282981872559 : Real Out 0.0\n",
      "Hyp -0.09133028984069824 : Real Out 0.0\n",
      "Hyp 0.996056318283081 : Real Out 1.0\n",
      "Hyp 0.9862451553344727 : Real Out 1.0\n",
      "Hyp 0.14194950461387634 : Real Out 0.0\n",
      "Hyp 0.06565538048744202 : Real Out 0.0\n",
      "Hyp 0.9772987961769104 : Real Out 1.0\n",
      "Hyp 0.9618489742279053 : Real Out 1.0\n",
      "Hyp 0.03690153360366821 : Real Out 0.0\n",
      "Hyp 0.23179268836975098 : Real Out 0.0\n",
      "Hyp 1.0115094184875488 : Real Out 1.0\n",
      "Hyp 0.9201003313064575 : Real Out 1.0\n",
      "Hyp 0.018614888191223145 : Real Out 0.0\n",
      "Hyp 0.0888509750366211 : Real Out 0.0\n",
      "Hyp 0.9247018098831177 : Real Out 1.0\n",
      "Hyp 1.0358253717422485 : Real Out 1.0\n",
      "Hyp 0.07351386547088623 : Real Out 0.0\n",
      "Hyp 0.0152740478515625 : Real Out 0.0\n",
      "Hyp 1.0315605401992798 : Real Out 1.0\n",
      "Hyp 1.0340768098831177 : Real Out 1.0\n",
      "Hyp 0.0678684413433075 : Real Out 0.0\n",
      "Hyp -0.018745779991149902 : Real Out 0.0\n",
      "Hyp 1.0032585859298706 : Real Out 1.0\n",
      "Hyp 0.9985373616218567 : Real Out 1.0\n",
      "Hyp 0.1425498127937317 : Real Out 0.0\n",
      "Hyp 0.008264303207397461 : Real Out 0.0\n",
      "Hyp 0.9838150143623352 : Real Out 1.0\n",
      "Hyp 0.9276805520057678 : Real Out 1.0\n",
      "Hyp 0.040529221296310425 : Real Out 0.0\n",
      "Hyp 0.008358597755432129 : Real Out 0.0\n",
      "Hyp 1.0436265468597412 : Real Out 1.0\n",
      "Hyp 0.9563822746276855 : Real Out 1.0\n",
      "Hyp 0.0834357738494873 : Real Out 0.0\n",
      "Hyp -0.0013968348503112793 : Real Out 0.0\n",
      "Hyp 0.9945195317268372 : Real Out 1.0\n",
      "Hyp 1.0595171451568604 : Real Out 1.0\n",
      "Hyp -0.063690185546875 : Real Out 0.0\n",
      "Hyp -0.0020427405834198 : Real Out 0.0\n",
      "Hyp 0.9588208198547363 : Real Out 1.0\n",
      "Hyp 1.0327792167663574 : Real Out 1.0\n",
      "Hyp 0.012944519519805908 : Real Out 0.0\n",
      "Hyp 0.026112645864486694 : Real Out 0.0\n",
      "Hyp 0.9589730501174927 : Real Out 1.0\n",
      "Hyp 1.0158225297927856 : Real Out 1.0\n",
      "Hyp -0.03416275978088379 : Real Out 0.0\n",
      "Hyp 0.04688233137130737 : Real Out 0.0\n",
      "Hyp 1.0302233695983887 : Real Out 1.0\n",
      "Hyp 0.945716142654419 : Real Out 1.0\n",
      "Hyp -0.06686073541641235 : Real Out 0.0\n",
      "Hyp 0.14899975061416626 : Real Out 0.0\n",
      "Hyp 0.9525649547576904 : Real Out 1.0\n",
      "Hyp 0.9788845181465149 : Real Out 1.0\n",
      "Hyp 0.14564454555511475 : Real Out 0.0\n",
      "Hyp 0.017149746417999268 : Real Out 0.0\n",
      "Hyp 0.9556138515472412 : Real Out 1.0\n",
      "Hyp 1.0165153741836548 : Real Out 1.0\n",
      "Hyp 0.02982303500175476 : Real Out 0.0\n",
      "Hyp 0.08156707882881165 : Real Out 0.0\n",
      "Hyp 0.9424420595169067 : Real Out 1.0\n",
      "Hyp 0.9095723032951355 : Real Out 1.0\n",
      "Hyp -0.04618555307388306 : Real Out 0.0\n",
      "Hyp -0.034135401248931885 : Real Out 0.0\n",
      "Hyp 1.0465121269226074 : Real Out 1.0\n",
      "Hyp 0.9947708249092102 : Real Out 1.0\n",
      "Hyp -0.09131878614425659 : Real Out 0.0\n",
      "Hyp 0.026494890451431274 : Real Out 0.0\n",
      "Hyp 1.000128149986267 : Real Out 1.0\n",
      "Hyp 1.0252130031585693 : Real Out 1.0\n",
      "Hyp 0.09367808699607849 : Real Out 0.0\n",
      "Hyp 0.09202402830123901 : Real Out 0.0\n",
      "Hyp 0.9622989892959595 : Real Out 1.0\n",
      "Hyp 0.9884305596351624 : Real Out 1.0\n",
      "Hyp 0.045680731534957886 : Real Out 0.0\n",
      "Hyp -0.03184455633163452 : Real Out 0.0\n",
      "Hyp 0.9555304050445557 : Real Out 1.0\n",
      "Hyp 1.0169165134429932 : Real Out 1.0\n",
      "Hyp -0.13422489166259766 : Real Out 0.0\n",
      "Hyp -0.022585809230804443 : Real Out 0.0\n",
      "Hyp 0.9478445053100586 : Real Out 1.0\n",
      "Hyp 0.9647555351257324 : Real Out 1.0\n",
      "Hyp -0.006391018629074097 : Real Out 0.0\n",
      "Hyp 0.09318724274635315 : Real Out 0.0\n",
      "Hyp 0.9501725435256958 : Real Out 1.0\n",
      "Hyp 0.9736194610595703 : Real Out 1.0\n",
      "Hyp 0.08521386981010437 : Real Out 0.0\n",
      "Hyp 0.09002548456192017 : Real Out 0.0\n",
      "Hyp 0.9755130410194397 : Real Out 1.0\n",
      "Hyp 0.934722900390625 : Real Out 1.0\n",
      "Hyp -0.034239113330841064 : Real Out 0.0\n",
      "Hyp 0.0012425482273101807 : Real Out 0.0\n",
      "Hyp 0.9546510577201843 : Real Out 1.0\n",
      "Hyp 1.056913137435913 : Real Out 1.0\n",
      "Hyp -0.015049636363983154 : Real Out 0.0\n",
      "Hyp 0.08767986297607422 : Real Out 0.0\n",
      "Hyp 0.9028024673461914 : Real Out 1.0\n",
      "Hyp 1.0511019229888916 : Real Out 1.0\n",
      "Hyp -0.018970251083374023 : Real Out 0.0\n",
      "Hyp -0.02865546941757202 : Real Out 0.0\n",
      "Hyp 1.0453293323516846 : Real Out 1.0\n",
      "Hyp 0.9797006845474243 : Real Out 1.0\n",
      "Hyp 0.01312476396560669 : Real Out 0.0\n",
      "Hyp 0.07769522070884705 : Real Out 0.0\n",
      "Hyp 0.9643286466598511 : Real Out 1.0\n",
      "Hyp 0.9941482543945312 : Real Out 1.0\n",
      "Hyp -0.05595976114273071 : Real Out 0.0\n",
      "Hyp 0.021114885807037354 : Real Out 0.0\n",
      "Hyp 0.973242461681366 : Real Out 1.0\n",
      "Hyp 1.0013831853866577 : Real Out 1.0\n",
      "Hyp 0.014034152030944824 : Real Out 0.0\n",
      "Hyp 0.046066612005233765 : Real Out 0.0\n",
      "Hyp 0.9590365886688232 : Real Out 1.0\n",
      "Hyp 0.9956754446029663 : Real Out 1.0\n",
      "Hyp 0.010532081127166748 : Real Out 0.0\n",
      "Hyp -0.07484227418899536 : Real Out 0.0\n",
      "Hyp 0.9945737719535828 : Real Out 1.0\n",
      "Hyp 1.0061585903167725 : Real Out 1.0\n",
      "Hyp -0.10603374242782593 : Real Out 0.0\n",
      "Hyp 0.07185035943984985 : Real Out 0.0\n",
      "Hyp 0.9691616892814636 : Real Out 1.0\n",
      "Hyp 1.0481911897659302 : Real Out 1.0\n",
      "Hyp -0.011213958263397217 : Real Out 0.0\n",
      "Hyp 0.01283767819404602 : Real Out 0.0\n",
      "Hyp 0.9937341213226318 : Real Out 1.0\n",
      "Hyp 1.0117194652557373 : Real Out 1.0\n",
      "Hyp 0.08712461590766907 : Real Out 0.0\n",
      "Hyp 0.012994050979614258 : Real Out 0.0\n",
      "Hyp 0.9824919700622559 : Real Out 1.0\n",
      "Hyp 1.0529627799987793 : Real Out 1.0\n",
      "Hyp -0.16061002016067505 : Real Out 0.0\n",
      "Hyp -0.07776689529418945 : Real Out 0.0\n",
      "Hyp 0.9587115049362183 : Real Out 1.0\n",
      "Hyp 0.9772604703903198 : Real Out 1.0\n",
      "Hyp 0.0690491795539856 : Real Out 0.0\n",
      "Hyp 0.01176193356513977 : Real Out 0.0\n",
      "Hyp 0.937893271446228 : Real Out 1.0\n",
      "Hyp 0.9700434803962708 : Real Out 1.0\n",
      "Hyp 0.06702756881713867 : Real Out 0.0\n",
      "Hyp -0.08510482311248779 : Real Out 0.0\n",
      "Hyp 0.9680116176605225 : Real Out 1.0\n",
      "Hyp 0.9543569684028625 : Real Out 1.0\n",
      "Hyp 0.12161755561828613 : Real Out 0.0\n",
      "Hyp -0.0823366641998291 : Real Out 0.0\n",
      "Hyp 0.9793083667755127 : Real Out 1.0\n",
      "Hyp 1.1032856702804565 : Real Out 1.0\n",
      "Hyp -0.09087437391281128 : Real Out 0.0\n",
      "Hyp 0.023565828800201416 : Real Out 0.0\n",
      "Hyp 0.972267210483551 : Real Out 1.0\n",
      "Hyp 1.0390286445617676 : Real Out 1.0\n",
      "Hyp 0.09881946444511414 : Real Out 0.0\n",
      "Hyp 0.12250599265098572 : Real Out 0.0\n"
     ]
    }
   ],
   "source": [
    "# source: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-custom-nn-modules\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "#N, D_in, H, D_out = 64, 10, 10, 1\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "#x = torch.randn(N, D_in)\n",
    "#y = torch.randn(N, D_out)\n",
    "\n",
    "# move to device \n",
    "x = x.to(device)\n",
    "y = y.to(device) \n",
    "\n",
    "print(f\"input dim {x.shape}\")\n",
    "print(f\"Input {x[0,:]} -> output {y[0]}\")\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#print the model\n",
    "print(model)\n",
    "modelParameters = sum([param.nelement() for param in model.parameters()])\n",
    "print('Num Model Parameters ', modelParameters )\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(1000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 200 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_Actual  y_Predicted\n",
      "0       1.0          1.0\n",
      "1       1.0          1.0\n",
      "2       0.0          0.0\n",
      "3       0.0          0.0\n",
      "4       1.0          1.0\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        202    0\n",
      "1.0          0  202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaeb\" ><thead>    <tr>        <th class=\"index_name level0\" >Predicted</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1.0</th>    </tr>    <tr>        <th class=\"index_name level0\" >Actual</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaeblevel0_row0\" class=\"row_heading level0 row0\" >0.0</th>\n",
       "                        <td id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaebrow0_col0\" class=\"data row0 col0\" >202</td>\n",
       "                        <td id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaebrow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaeblevel0_row1\" class=\"row_heading level0 row1\" >1.0</th>\n",
       "                        <td id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaebrow1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_54a1ab2c_e568_11ea_8f79_00d8614ecaebrow1_col1\" class=\"data row1 col1\" >202</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17329293988>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "y = y.to('cpu')\n",
    "npActual    = list(torch.squeeze(y).numpy())\n",
    "\n",
    "\n",
    "# evaluate\n",
    "out = model(x)\n",
    "out = out.to('cpu')\n",
    "out = torch.squeeze((out)) \n",
    "npPredicted = out.detach().numpy()\n",
    "npPredicted[npPredicted>0.5]  = 1\n",
    "npPredicted[npPredicted<=0.5] = 0\n",
    "\n",
    "data = {'y_Actual':    npActual,\n",
    "        'y_Predicted': list(npPredicted)\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "confusion_matrix.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400\n",
      "   y_Actual  y_Predicted\n",
      "0         1          1.0\n",
      "1         1          1.0\n",
      "2         0          0.0\n",
      "3         0          0.0\n",
      "4         1          1.0\n",
      "Predicted  0.0  1.0\n",
      "Actual             \n",
      "0          170   30\n",
      "1            4  196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_8530b098_e569_11ea_bc99_00d8614ecaeb\" ><thead>    <tr>        <th class=\"index_name level0\" >Predicted</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1.0</th>    </tr>    <tr>        <th class=\"index_name level0\" >Actual</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8530b098_e569_11ea_bc99_00d8614ecaeblevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_8530b098_e569_11ea_bc99_00d8614ecaebrow0_col0\" class=\"data row0 col0\" >170</td>\n",
       "                        <td id=\"T_8530b098_e569_11ea_bc99_00d8614ecaebrow0_col1\" class=\"data row0 col1\" >30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8530b098_e569_11ea_bc99_00d8614ecaeblevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_8530b098_e569_11ea_bc99_00d8614ecaebrow1_col0\" class=\"data row1 col0\" >4</td>\n",
       "                        <td id=\"T_8530b098_e569_11ea_bc99_00d8614ecaebrow1_col1\" class=\"data row1 col1\" >196</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17328aa7488>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XEvalData = npPos\n",
    "YEvalData = npOut\n",
    "for ii in range(99):\n",
    "    noise = np.random.normal(size=(4,4)) #/ 5\n",
    "    npPos1 = npPos+noise\n",
    "    XEvalData = np.concatenate((XEvalData, npPos1), axis=0)\n",
    "    YEvalData = np.concatenate((YEvalData, npOut ), axis=0)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "x = torch.from_numpy(XEvalData.astype(np.float32))\n",
    "x = x.to(device)\n",
    "out = model(x)\n",
    "out = out.to('cpu')\n",
    "out = torch.squeeze((out)) \n",
    "npPredicted = out.detach().numpy()\n",
    "npPredicted[npPredicted>0.5]  = 1\n",
    "npPredicted[npPredicted<=0.5] = 0\n",
    "\n",
    "data = {'y_Actual':    list(YEvalData),\n",
    "        'y_Predicted': list(npPredicted)\n",
    "        }\n",
    "print(len(data['y_Actual']), len(data['y_Predicted']))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "confusion_matrix.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start building our own neural network model, we can define a class that inherits PyTorchs base class (nn.module) for all neural network modules. After doing so, we can start defining some variables and also the layers for our model under the constructor. For this model, well only be using 1 layer of RNN followed by a fully connected layer. The fully connected layer will be in-charge of converting the RNN output to our desired output shape.\n",
    "\n",
    "Well also have to define the forward pass function under forward() as a class method. The order the forward function is sequentially executed, therefore well have to pass the inputs and the zero-initialized hidden state through the RNN layer first, before passing the RNN outputs to the fully-connected layer. Note that we are using the layers that we defined in the constructor.\n",
    "\n",
    "The last method that we have to define is the method that we called earlier to initialize the hidden state - init_hidden(). This basically creates a tensor of zeros in the shape of our hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the model above, we'll have to instantiate the model with the relevant parameters and define our hyperparamters as well. The hyperparameters we're defining below are:\n",
    "\n",
    "- *n_epochs*: Number of Epochs --> This refers to the number of times our model will go through the entire training dataset\n",
    "- *lr*: Learning Rate --> This affects the rate at which our model updates the weights in the cells each time backpropogation is done\n",
    "    - A smaller learning rate means that the model changes the values of the weight with a smaller magnitude\n",
    "    - A larger learning rate means that the weights are updated to a larger extent for each time step\n",
    "\n",
    "Similar to other neural networks, we have to define the optimizer and loss function as well. Well be using CrossEntropyLoss as the final output is basically a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runAllCells:\n",
    "\n",
    "    #Returns the index of a currently selected device.\n",
    "    print(f\"Currently selected device {torch.cuda.current_device()}\")\n",
    "\n",
    "    print(f\"Returns the number of GPUs available {torch.cuda.device_count()}\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def saveModel(testDes, model, epoch, loss):\n",
    "    basePath = \"C:\\\\Users\\\\tzurv\\\\python\\\\GoogleCloud\\\\testOutput\"\n",
    "    dir = os.path.join(basePath, testDes, str(epoch))\n",
    "    #print(dir)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)   \n",
    "    fileName = dir+\"\\\\modelNN.pt\"\n",
    "    print(f\"saving {fileName}\")\n",
    "    torch.save(model, fileName)\n",
    "    \n",
    "    outFile = open(dir+'\\\\loss.txt', 'w')\n",
    "    outFile.write(f\"{loss}\\n\")\n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-e78ca5a14b21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Instantiate the model with hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# We'll also set the model to the device that we defined earlier (default is CPU)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=200, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 4\n",
    "lr=0.001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=char2int[ignoreChar])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-8500bae4a2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodelParameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Num Model Parameters '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelParameters\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#print the model\n",
    "print(model)\n",
    "modelParameters = sum([param.nelement() for param in model.parameters()])\n",
    "print('Num Model Parameters ', modelParameters )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin our training! As we only have a few sentences, this training process is very fast. However, as we progress, larger datasets and deeper models mean that the input data is much larger and the number of parameters within the model that we have to compute is much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200/4000............. Loss: 1.5599\n",
      "Epoch: 400/4000............. Loss: 1.5273\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\400\\modelNN.pt\n",
      "Epoch: 600/4000............. Loss: 1.5134\n",
      "Epoch: 800/4000............. Loss: 1.5050\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\800\\modelNN.pt\n",
      "Epoch: 1000/4000............. Loss: 1.4993\n",
      "Epoch: 1200/4000............. Loss: 1.4950\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\1200\\modelNN.pt\n",
      "Epoch: 1400/4000............. Loss: 1.4919\n",
      "Epoch: 1600/4000............. Loss: 1.4892\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\1600\\modelNN.pt\n",
      "Epoch: 1800/4000............. Loss: 1.4869\n",
      "Epoch: 2000/4000............. Loss: 1.4853\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\2000\\modelNN.pt\n",
      "Epoch: 2200/4000............. Loss: 1.4834\n",
      "Epoch: 2400/4000............. Loss: 1.4822\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\2400\\modelNN.pt\n",
      "Epoch: 2600/4000............. Loss: 1.4810\n",
      "Epoch: 2800/4000............. Loss: 1.4801\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\2800\\modelNN.pt\n",
      "Epoch: 3000/4000............. Loss: 1.4789\n",
      "Epoch: 3200/4000............. Loss: 1.4782\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\3200\\modelNN.pt\n",
      "Epoch: 3400/4000............. Loss: 1.4772\n",
      "Epoch: 3600/4000............. Loss: 1.4766\n",
      "saving C:\\Users\\tzurv\\python\\GoogleCloud\\testOutput\\20200805_4000_2000_0.001_P63658\\3600\\modelNN.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6813d9ad7f11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Clears existing gradients from previous epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mbatch_input_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_input_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "totSentences = input_seq.shape[0]\n",
    "batchSize = 2000\n",
    "\n",
    "testDes = \"20200805_\"+str(n_epochs)+\"_\"+str(batchSize)+\"_\"+str(lr)+\"_P\"+str(modelParameters)\n",
    "\n",
    "# Training Run\n",
    "#input_seq = input_seq.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    totLoss = 0\n",
    "    batchNo = 0\n",
    "    for start in range(0, totSentences, batchSize):\n",
    "    \n",
    "        # get batch data\n",
    "        batchNo += 1\n",
    "        batch_input_seq  = input_seq[start:start+batchSize,  :, :]\n",
    "        batch_target_seq = target_seq[start:start+batchSize, :   ]\n",
    "    \n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "\n",
    "        batch_input_seq = batch_input_seq.to(device)\n",
    "        output, hidden = model(batch_input_seq)\n",
    "        output = output.to(device)\n",
    "        batch_target_seq = batch_target_seq.to(device)\n",
    "\n",
    "        loss = criterion(output, batch_target_seq.view(-1).long())\n",
    "        totLoss += loss.item()\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%200 == 0:\n",
    "    #if True:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(totLoss/batchNo))\n",
    "        if epoch%400 == 0:\n",
    "            saveModel(testDes, model, epoch, loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test our model now and see what kind of output we will get. Before that, lets define some helper function to convert our model output back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    character = character.to(device)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    #print(prob)\n",
    "    \n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "    #print(char_ind)\n",
    "\n",
    "    return int2char[char_ind], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, out_len, start=' '):\n",
    "    #print(\"Eval output\")\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "        \n",
    "        #print(ii, f\"!{char}!\")\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is able to come up with the sentence good i am fine  if we feed it with the words good, achieving what we intended for it to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400,  loss is 1.533184289932251\n",
      "!         !\n",
      "800,  loss is 1.5066548585891724\n",
      "!           !\n",
      "1200,  loss is 1.4946609735488892\n",
      "! .        !\n",
      "1600,  loss is 1.4875528812408447\n",
      "!          !\n",
      "2000,  loss is 1.4801770448684692\n",
      "!         !\n",
      "2400,  loss is 1.4757835865020752\n",
      "!          !\n",
      "2800,  loss is 1.4737255573272705\n",
      "!           !\n",
      "3200,  loss is 1.4719035625457764\n",
      "!            !\n",
      "3600,  loss is 1.4693256616592407\n",
      "!           !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "PATH = \"C:\\\\Users\\\\tzurv\\\\python\\\\GoogleCloud\\\\testOutput\\\\\" +testDes + \"\\\\\"\n",
    "os.chdir(PATH)\n",
    "\n",
    "files = glob.glob(\"*\")\n",
    "prvPredictedOut = \"\"\n",
    "for indx in sorted(files, key = int):\n",
    "    modelFileName = PATH + \"\\\\\" + indx + \"\\\\modelNN.pt\"\n",
    "    \n",
    "    # Model class must be defined somewhere\n",
    "    model = torch.load(modelFileName)\n",
    "    model.eval()\n",
    "    \n",
    "    predictedOut = sample(model, 50, ' ')\n",
    "    if not predictedOut == prvPredictedOut:\n",
    "        # get loss\n",
    "        lossFile = open(PATH + \"\\\\\" + indx + \"\\\\loss.txt\" , 'rt')\n",
    "        loss = lossFile.readline().rstrip()\n",
    "        lossFile.close()\n",
    "        \n",
    "        # print information\n",
    "        print(f\"{indx},  loss is {loss}\")\n",
    "        print(f\"!{predictedOut}!\")\n",
    "        \n",
    "        # store last prediction\n",
    "        prvPredictedOut = predictedOut\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400,  loss is 1.533184289932251\n",
      "! ,   ,     !\n",
      "800,  loss is 1.5066548585891724\n",
      "! ,   ,     !\n",
      "1200,  loss is 1.4946609735488892\n",
      "! ,   ,     !\n",
      "1600,  loss is 1.4875528812408447\n",
      "! ,   ,     !\n",
      "2400,  loss is 1.4757835865020752\n",
      "! ,  ,      !\n",
      "2800,  loss is 1.4737255573272705\n",
      "! ,  ,       !\n",
      "3200,  loss is 1.4719035625457764\n",
      "! ,  ,      !\n",
      "3600,  loss is 1.4693256616592407\n",
      "! ,  ,      !\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "PATH = \"C:\\\\Users\\\\tzurv\\\\python\\\\GoogleCloud\\\\testOutput\\\\\" +testDes + \"\\\\\"\n",
    "os.chdir(PATH)\n",
    "\n",
    "files = glob.glob(\"*\")\n",
    "prvPredictedOut = \"\"\n",
    "for indx in sorted(files, key = int):\n",
    "    modelFileName = PATH + \"\\\\\" + indx + \"\\\\modelNN.pt\"\n",
    "    \n",
    "    # Model class must be defined somewhere\n",
    "    model = torch.load(modelFileName)\n",
    "    model.eval()\n",
    "    \n",
    "    predictedOut = sample(model, 50, ' , ')\n",
    "    if not predictedOut == prvPredictedOut:\n",
    "        # get loss\n",
    "        lossFile = open(PATH + \"\\\\\" + indx + \"\\\\loss.txt\" , 'rt')\n",
    "        loss = lossFile.readline().rstrip()\n",
    "        lossFile.close()\n",
    "        \n",
    "        # print information\n",
    "        print(f\"{indx},  loss is {loss}\")\n",
    "        print(f\"!{predictedOut}!\")\n",
    "        \n",
    "        # store last prediction\n",
    "        prvPredictedOut = predictedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(model, 50, ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scraper",
   "language": "python",
   "name": "scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
