{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/\n",
    "\n",
    "# ------------- IPython Magic Commands --------------\n",
    "%lsmagic\n",
    "\n",
    "%debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by importing the main PyTorch package along with the *Variable* class used to store our data tensors and the *nn* package which we will use when building the model. In addition, we'll only be using numpy to pre-process our data as Torch works really well with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1, 2, 3, 4])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n",
      "   y_Actual  y_Predicted\n",
      "0         1            1\n",
      "1         0            1\n",
      "2         0            0\n",
      "3         1            1\n",
      "4         0            0\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          5  2\n",
      "1          1  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaeb\" ><thead>    <tr>        <th class=\"index_name level0\" >Predicted</th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>    </tr>    <tr>        <th class=\"index_name level0\" >Actual</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaeblevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow0_col0\" class=\"data row0 col0\" >5</td>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow0_col1\" class=\"data row0 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaeblevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_4814123e_e564_11ea_a6c7_00d8614ecaebrow1_col1\" class=\"data row1 col1\" >4</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17328a9fa08>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://datatofish.com/confusion-matrix-python/\n",
    "\n",
    "import pandas as pd\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "\n",
    "data = {'y_Actual':    [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
    "        'y_Predicted': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
    "        }\n",
    "\n",
    "print(len(data['y_Actual']), len(data['y_Predicted']))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print(df.head())\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "confusion_matrix.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn\n",
    "source https://towardsdatascience.com/pytorch-tabular-binary-classification-a0368da5bb89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-273-7747ba257730>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "###################### OUTPUT ######################\n",
    "array([[23,  8],\n",
    "       [12, 60]])\n",
    "\n",
    "#Classification Report\n",
    "\n",
    "print(classification_report(y_test, y_pred_list))\n",
    "\n",
    "###################### OUTPUT ######################\n",
    "precision    recall  f1-score   support\n",
    "           0       0.66      0.74      0.70        31\n",
    "           1       0.88      0.83      0.86        72\n",
    "    accuracy                           0.81       103\n",
    "   macro avg       0.77      0.79      0.78       103\n",
    "weighted avg       0.81      0.81      0.81       103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/get-started/locally/#mac-anaconda\n",
    "# conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dammy train test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create to typ of x^3 data sets predicting the next 2 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23309093 0.45164794 0.05867559 0.48031216]\n",
      "[ 0.46153371 -0.15806776 -0.22464431  3.21391268]\n",
      "[ 1.98233027  0.42121132 -1.81317508 -2.03645184]\n",
      "[-0.79195265 -0.70955964 -2.82003918  0.28133835]\n",
      "[[ 0.          0.1         0.3         0.5       ]\n",
      " [ 0.5        -0.2        -0.2         3.        ]\n",
      " [ 2.          0.3        -1.5        -2.        ]\n",
      " ...\n",
      " [ 0.37721847 -0.19278121  0.08896957  2.58344273]\n",
      " [ 2.04513343  0.19070594 -1.10348105 -2.29168139]\n",
      " [-0.64605173 -0.40244924 -2.68544393  0.20519928]]\n",
      "[1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      " 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "import glob, os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def func(x, a, b, c, d):\n",
    "    ''' ~x^3 curve     '''\n",
    "    return a + b * x + c * x * x + d * pow(x,3)\n",
    "\n",
    "\n",
    "Pos = [ [0, 0.1 , 0.3, 0.5],\n",
    "        [0.5, -0.2 , -0.2, 3],\n",
    "       [2, 0.3, -1.5, -2],\n",
    "       [-0.5, -0.7, -3, 0.1]]\n",
    "\n",
    "out = [1 ,1 , 0 , 0]\n",
    "   \n",
    "npPos = np.array(Pos)\n",
    "npOut = np.array(out)\n",
    "\n",
    "noise = np.random.normal(size=(4,4)) / 5\n",
    "npPos1 = npPos+noise\n",
    "\n",
    "#https://matplotlib.org/gallery/subplots_axes_and_figures/demo_constrained_layout.html#sphx-glr-gallery-subplots-axes-and-figures-demo-constrained-layout-py\n",
    "fig1, f1_axes = plt.subplots(ncols=2, nrows=2, constrained_layout=True)\n",
    "xData = np.linspace(-5, 5, 20)\n",
    "for V, ax in zip(npPos1, f1_axes.flat):\n",
    "    print(V)\n",
    "    yData = func(xData, *V)\n",
    "    ax.plot(xData, yData)\n",
    "    #ax.set_xlabel(str(V))\n",
    "fig1.show()\n",
    "\n",
    "\n",
    "XtrainData = npPos\n",
    "YtrainData = npOut\n",
    "for ii in range(100):\n",
    "    noise = np.random.normal(size=(4,4)) / 5\n",
    "    npPos1 = npPos+noise\n",
    "    XtrainData = np.concatenate((XtrainData, npPos1), axis=0)\n",
    "    YtrainData = np.concatenate((YtrainData, npOut ), axis=0)\n",
    "    \n",
    "print(XtrainData)\n",
    "print(YtrainData)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=404, minmax=(array([-0.97260027, -1.22371437, -3.43682258, -2.4760504 ]), array([2.43043601, 0.82227406, 0.80832865, 3.44876933])), mean=array([ 0.50638901, -0.12127   , -1.09099845,  0.39223615]), variance=array([0.93116924, 0.17126754, 1.64759804, 3.18037375]), skewness=array([ 0.64149874, -0.32503349, -0.40527708,  0.16540964]), kurtosis=array([-0.94009782, -0.57536076, -1.29824994, -0.98818048]))\n",
      "[ 0.50638901 -0.12127    -1.09099845  0.39223615]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "trainStat = stats.describe(XtrainData)\n",
    "print(trainStat)\n",
    "print(trainStat.mean)\n",
    "normalizedTrain = (XtrainData - trainStat.mean) / np.sqrt(trainStat.variance)\n",
    "stats.describe(normalizedTrain)\n",
    "\n",
    "print(type(XtrainData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "class dataNormalization:\n",
    "    ''' Data normalization class'''\n",
    "    def __init__(self, data):\n",
    "        self.initialized = False\n",
    "        if not type(data) is np.ndarray:\n",
    "            raise ValueError('dataNormalization required numpy array for initialization')\n",
    "        self.dataStat = stats.describe(data)\n",
    "        self.initialized = True\n",
    "\n",
    "    def normalize(self, data):\n",
    "        return (data - self.dataStat.mean) / np.sqrt(self.dataStat.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=111, minmax=(array([-1.16199716, -1.07496484, -1.07740654, -1.03376257, -0.96967635,\n",
       "       -0.97457294, -1.07431851, -1.06731467, -4.97847921, -4.38087788,\n",
       "       -2.99715475]), array([4.57249159, 4.12055953, 3.95491047, 4.86507348, 5.23838866,\n",
       "       4.97839842, 3.53414695, 4.14716673, 2.35705204, 1.52000559,\n",
       "       3.95753523])), mean=array([ 6.14123367e-16,  3.78075949e-16,  5.09102270e-16,  5.17103877e-16,\n",
       "       -8.00160738e-18, -1.22024513e-16, -6.60132609e-16,  6.52131002e-16,\n",
       "        3.15063291e-17,  8.42669278e-17,  1.13366523e-16]), variance=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), skewness=array([ 1.75898415,  1.8791425 ,  1.80646565,  2.17586148,  2.42820172,\n",
       "        2.3257104 ,  1.71644796,  1.96629504, -1.39608577, -1.79308595,\n",
       "        0.73548092]), kurtosis=array([4.29043447, 4.36595382, 3.67390382, 5.85934911, 7.53238429,\n",
       "       6.57546331, 2.74370007, 4.37466945, 5.55490904, 5.03146094,\n",
       "       2.65837196]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dNorm = dataNormalization(XtrainData)\n",
    "stats.describe(dNorm.normalize(XtrainData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllCells = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data created by Predict.py into 2 files\n",
    "20200824_Train.csv : trainin data\n",
    "20200824_Eval.csv  : eval data containes last week data\n",
    "last column is the classification \n",
    "1: Not getting worst\n",
    "0: getting worst by more than 10% or into negative territory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16792423e+01  1.03812891e+01  7.39674330e+00  6.55524495e+00\n",
      "   6.97537355e+00  6.97537355e+00  6.13635506e+00  7.07420043e+00\n",
      "  -5.18620103e-01  2.35007813e-01 -4.76556096e-02  0.00000000e+00]\n",
      " [ 1.97089821e+01  1.16792423e+01  1.03812891e+01  7.39674330e+00\n",
      "   6.55524495e+00  6.97537355e+00  6.97537355e+00  7.42816873e+00\n",
      "  -1.01956495e+00  6.31252418e-01 -1.16769330e-01  0.00000000e+00]\n",
      " [ 7.81935663e+00  1.97089821e+01  1.16792423e+01  1.03812891e+01\n",
      "   7.39674330e+00  6.55524495e+00  6.97537355e+00  1.12537218e+01\n",
      "  -4.40919724e+00 -2.94993595e-01  4.60895919e-01  1.00000000e+00]\n",
      " [ 1.60962563e+00  7.81935663e+00  1.97089821e+01  1.16792423e+01\n",
      "   1.03812891e+01  7.39674330e+00  6.55524495e+00  1.38864229e+01\n",
      "  -2.69097189e+00 -1.14480274e+00  4.08220160e-01  1.00000000e+00]\n",
      " [ 7.18786551e+01  5.23548331e+01  4.85512442e+01  3.70594684e+01\n",
      "   3.75668606e+01  3.50439223e+01  4.16768859e+01  3.86290520e+01\n",
      "  -4.49399344e+00  1.91887520e+00 -5.29576337e-02  1.00000000e+00]]\n",
      "(111, 11)\n",
      "(111,)\n",
      "[[ 1.03812891e+01  7.39674330e+00  6.55524495e+00  6.97537355e+00\n",
      "   6.97537355e+00  6.13635506e+00  2.01505006e+00  6.94371156e+00\n",
      "   4.91978988e-01 -7.75196917e-02 -2.09054982e-01  1.00000000e+00]\n",
      " [ 5.23548331e+01  4.85512442e+01  3.70594684e+01  3.75668606e+01\n",
      "   3.50439223e+01  4.16768859e+01  4.16768859e+01  3.70575867e+01\n",
      "  -1.35940016e+00  1.23310691e+00 -4.96678557e-02  0.00000000e+00]\n",
      " [ 6.55524495e+00  9.52229478e+00  1.21144263e+01  7.81935663e+00\n",
      "   3.23860521e+00  2.82953744e+00 -9.63121094e+00  9.05052925e+00\n",
      "  -2.40916801e+00 -1.10376608e+00 -1.71632619e-02  0.00000000e+00]\n",
      " [ 2.39093442e+02  1.70117114e+02  1.25923746e+02  1.22260689e+02\n",
      "   7.55097690e+01  9.12622617e+01  8.93180613e+01  1.04368621e+02\n",
      "  -1.94929659e+01  6.53231210e+00 -5.69626423e-01  0.00000000e+00]\n",
      " [ 5.21625068e+02  3.77197035e+02  2.24347133e+02  1.95400188e+02\n",
      "   1.28886641e+02  1.41805299e+02  7.98184449e+01  1.82920187e+02\n",
      "  -4.59849568e+01  1.38799464e+01 -3.08206655e+00  0.00000000e+00]]\n",
      "(34, 11)\n",
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\\\Users\\\\tzurv\\\\python\\\\VScode\\\\scraper\\\\\"\n",
    "dateStamp = \"20200824\"\n",
    "TrainFileName = PATH + dateStamp + \"_Train.csv\"\n",
    "EvalFileName  = PATH + dateStamp + \"_Eval.csv\"\n",
    "\n",
    "\n",
    "allTrainingData =  np.genfromtxt(TrainFileName, delimiter=',') \n",
    "print(allTrainingData[0:5,:])\n",
    "#print(allTrainingData.shape)\n",
    "XtrainData = allTrainingData[:,0:-1]\n",
    "#print(XtrainData[0:5,:])\n",
    "print(XtrainData.shape)\n",
    "\n",
    "YtrainData = allTrainingData[:,-1]\n",
    "print(YtrainData.shape)\n",
    "#print(YtrainData[0:5])\n",
    "\n",
    "\n",
    "allEvalData =  np.genfromtxt(EvalFileName, delimiter=',') \n",
    "print(allEvalData[0:5,:])\n",
    "XEvalData = allEvalData[:,0:-1]\n",
    "#print(XtrainData[0:5,:])\n",
    "print(XEvalData.shape)\n",
    "\n",
    "YEvalData = allEvalData[:,-1]\n",
    "print(YEvalData.shape)\n",
    "#print(YtrainData[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data\n",
    "https://towardsdatascience.com/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32\n",
    "\n",
    "https://www.investopedia.com/terms/v/variance-inflation-factor.asp\n",
    "KEY TAKEAWAYS\n",
    "A variance inflation factor (VIF) provides a measure of multicollinearity among the independent variables in a multiple regression model.\n",
    "Detecting multicollinearity is important because while it does not reduce the explanatory power of the model, it does reduce the statistical significance of the independent variables. \n",
    "A large VIF on an independent variable indicates a highly collinear relationship to the other variables that should be considered or adjusted for in the structure of the model and selection of independent variables.\n",
    "\n",
    "=> A VIF of 1 indicates two variables are not correlated, a VIF between 1 and 5 indicates moderate correlation, and a VIF above 5 indicates high correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "<class 'tuple'>\n",
      "[0 1 2]\n",
      "[0 1 5]\n",
      "(111, 11)\n",
      "[[11.67924227 10.38128906  7.3967433   6.55524495  6.97537355  6.97537355\n",
      "   6.13635506  7.07420043 -0.5186201   0.23500781 -0.04765561]\n",
      " [19.70898215 11.67924227 10.38128906  7.3967433   6.55524495  6.97537355\n",
      "   6.97537355  7.42816873 -1.01956495  0.63125242 -0.11676933]]\n"
     ]
    }
   ],
   "source": [
    "a = [x for x in range(12)]\n",
    "print(a)\n",
    "b = list(itertools.combinations(a,3))\n",
    "#for c in itertools.combinations(a,3):\n",
    "#    print(c, type(c))\n",
    "print(type(b[0]))\n",
    "print(np.asarray(b[0]))\n",
    "col_idx = np.array([0, 1,  5])\n",
    "print(col_idx)\n",
    "print(XtrainData.shape)\n",
    "print(XtrainData[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------- 3 ------------\n",
      "   features  vif_Factor\n",
      "0         0    9.711988\n",
      "1         1    7.420000\n",
      "2         2    9.400578\n",
      "   features  vif_Factor\n",
      "0         0    6.723972\n",
      "1         1   10.261250\n",
      "2         3    8.109233\n",
      "   features  vif_Factor\n",
      "0         0    6.684981\n",
      "1         1    7.786339\n",
      "2         4    4.551736\n",
      "   features  vif_Factor\n",
      "0         0    7.454641\n",
      "1         1    6.940209\n",
      "2         5    4.642343\n",
      "   features  vif_Factor\n",
      "0         0    6.566093\n",
      "1         1    9.862382\n",
      "2         6    6.991178\n",
      "   features  vif_Factor\n",
      "0         0    7.045066\n",
      "1         1   10.094932\n",
      "2         7    8.930736\n",
      "   features  vif_Factor\n",
      "0         0    6.684604\n",
      "1         1   11.488979\n",
      "2         8    3.880719\n",
      "   features  vif_Factor\n",
      "0         0    6.689943\n",
      "1         1    7.978893\n",
      "2         9    1.565421\n",
      "   features  vif_Factor\n",
      "0         0   11.877004\n",
      "1         1   17.404261\n",
      "2        10    3.264714\n",
      "   features  vif_Factor\n",
      "0         0    7.894716\n",
      "1         2   17.757575\n",
      "2         3   11.076755\n",
      "   features  vif_Factor\n",
      "0         0    8.052203\n",
      "1         2   19.685734\n",
      "2         5   10.393593\n",
      "   features  vif_Factor\n",
      "0         0    7.894205\n",
      "1         2   15.986269\n",
      "2         6    8.944684\n",
      "   features  vif_Factor\n",
      "0         0    8.761329\n",
      "1         2    7.910028\n",
      "2         8    2.108911\n",
      "   features  vif_Factor\n",
      "0         0    7.975788\n",
      "1         2    8.474870\n",
      "2        10    1.254793\n",
      "   features  vif_Factor\n",
      "0         0    4.924301\n",
      "1         3   14.563217\n",
      "2         4   10.772627\n",
      "   features  vif_Factor\n",
      "0         0    5.170161\n",
      "1         3   10.417437\n",
      "2         5    8.817513\n",
      "   features  vif_Factor\n",
      "0         0    5.196937\n",
      "1         3   11.757015\n",
      "2         6   10.545959\n",
      "   features  vif_Factor\n",
      "0         0    5.654925\n",
      "1         3    4.974554\n",
      "2         8    2.126206\n",
      "   features  vif_Factor\n",
      "0         0    4.963861\n",
      "1         3    5.424044\n",
      "2        10    1.287458\n",
      "   features  vif_Factor\n",
      "0         0    4.420991\n",
      "1         4   14.085807\n",
      "2         6   17.080732\n",
      "   features  vif_Factor\n",
      "0         0    5.889096\n",
      "1         4    3.878898\n",
      "2         8    2.241276\n",
      "   features  vif_Factor\n",
      "0         0    7.966389\n",
      "1         4   16.831301\n",
      "2         9    5.648882\n",
      "   features  vif_Factor\n",
      "0         0    3.818924\n",
      "1         4    3.642284\n",
      "2        10    1.168745\n",
      "   features  vif_Factor\n",
      "0         0    4.571226\n",
      "1         5   15.128827\n",
      "2         6   16.032789\n",
      "   features  vif_Factor\n",
      "0         0    7.537302\n",
      "1         5    4.821928\n",
      "2         8    2.434932\n",
      "   features  vif_Factor\n",
      "0         0    6.488364\n",
      "1         5   11.081566\n",
      "2         9    3.250312\n",
      "   features  vif_Factor\n",
      "0         0    4.556649\n",
      "1         5    4.225669\n",
      "2        10    1.185005\n",
      "   features  vif_Factor\n",
      "0         0    5.565722\n",
      "1         6    4.417119\n",
      "2         8    2.104754\n",
      "   features  vif_Factor\n",
      "0         0    5.698433\n",
      "1         6    8.550841\n",
      "2         9    2.366622\n",
      "   features  vif_Factor\n",
      "0         0    4.421926\n",
      "1         6    4.738103\n",
      "2        10    1.253792\n",
      "   features  vif_Factor\n",
      "0         0    6.469315\n",
      "1         7    5.518386\n",
      "2         8    2.106973\n",
      "   features  vif_Factor\n",
      "0         0    5.540519\n",
      "1         7    5.945620\n",
      "2        10    1.260674\n",
      "   features  vif_Factor\n",
      "0         0    2.359161\n",
      "1         8    2.106541\n",
      "2         9    1.223567\n",
      "   features  vif_Factor\n",
      "0         0    1.335594\n",
      "1         9    1.257674\n",
      "2        10    1.202456\n",
      "   features  vif_Factor\n",
      "0         1    7.936064\n",
      "1         2   11.697093\n",
      "2         3   14.574224\n",
      "   features  vif_Factor\n",
      "0         1    6.061281\n",
      "1         2   13.844452\n",
      "2         4    9.738819\n",
      "   features  vif_Factor\n",
      "0         1    6.043132\n",
      "1         2   15.869134\n",
      "2         5   10.209801\n",
      "   features  vif_Factor\n",
      "0         1    7.531784\n",
      "1         2   10.154576\n",
      "2         6   11.170143\n",
      "   features  vif_Factor\n",
      "0         1   13.854961\n",
      "1         2    7.277926\n",
      "2         8    4.365136\n",
      "   features  vif_Factor\n",
      "0         1    6.370266\n",
      "1         2    8.302968\n",
      "2         9    2.007224\n",
      "   features  vif_Factor\n",
      "0         1   10.741908\n",
      "1         2    7.789188\n",
      "2        10    2.211994\n",
      "   features  vif_Factor\n",
      "0         1    7.611479\n",
      "1         3   19.326297\n",
      "2         4   10.911180\n",
      "   features  vif_Factor\n",
      "0         1    7.586826\n",
      "1         3   16.419926\n",
      "2         5    8.478671\n",
      "   features  vif_Factor\n",
      "0         1    8.443303\n",
      "1         3   12.717073\n",
      "2         6   11.227333\n",
      "   features  vif_Factor\n",
      "0         1   11.795075\n",
      "1         3   18.904582\n",
      "2         9    3.667938\n",
      "   features  vif_Factor\n",
      "0         1   13.153111\n",
      "1         3    9.808067\n",
      "2        10    2.235464\n",
      "   features  vif_Factor\n",
      "0         1    5.100486\n",
      "1         4    9.035402\n",
      "2         9    3.105127\n",
      "   features  vif_Factor\n",
      "0         1   11.429755\n",
      "1         4    7.439112\n",
      "2        10    3.003187\n",
      "   features  vif_Factor\n",
      "0         1    4.002348\n",
      "1         5    5.731398\n",
      "2         9    2.153570\n",
      "   features  vif_Factor\n",
      "0         1   12.570071\n",
      "1         5    7.954977\n",
      "2        10    3.511290\n",
      "   features  vif_Factor\n",
      "0         1    6.949085\n",
      "1         6    8.743007\n",
      "2         9    1.921438\n",
      "   features  vif_Factor\n",
      "0         1   11.951159\n",
      "1         6    8.738852\n",
      "2        10    2.256053\n",
      "   features  vif_Factor\n",
      "0         1   15.750114\n",
      "1         7   11.534047\n",
      "2        10    2.501023\n",
      "   features  vif_Factor\n",
      "0         1    5.926353\n",
      "1         8    4.436899\n",
      "2         9    1.788347\n",
      "   features  vif_Factor\n",
      "0         1    4.570384\n",
      "1         8   12.632021\n",
      "2        10    5.981010\n",
      "   features  vif_Factor\n",
      "0         1    2.288787\n",
      "1         9    1.470789\n",
      "2        10    1.727746\n",
      "   features  vif_Factor\n",
      "0         2   13.462923\n",
      "1         3   14.966066\n",
      "2         4   13.093907\n",
      "   features  vif_Factor\n",
      "0         2   15.294187\n",
      "1         3   12.605101\n",
      "2         5   11.596348\n",
      "   features  vif_Factor\n",
      "0         2   13.134158\n",
      "1         3   14.672805\n",
      "2         6   11.849328\n",
      "   features  vif_Factor\n",
      "0         2   11.479819\n",
      "1         3   11.185471\n",
      "2         8    1.918962\n",
      "   features  vif_Factor\n",
      "0         2   11.397851\n",
      "1         3   14.015660\n",
      "2         9    2.404758\n",
      "   features  vif_Factor\n",
      "0         2   11.076305\n",
      "1         3   11.390401\n",
      "2        10    1.277207\n",
      "   features  vif_Factor\n",
      "0         2   11.015707\n",
      "1         4   17.331485\n",
      "2         6   15.997597\n",
      "   features  vif_Factor\n",
      "0         2   18.522137\n",
      "1         4   13.512719\n",
      "2         8    2.649679\n",
      "   features  vif_Factor\n",
      "0         2   10.423050\n",
      "1         4   14.166253\n",
      "2         9    2.778122\n",
      "   features  vif_Factor\n",
      "0         2   12.179572\n",
      "1         4   10.932147\n",
      "2        10    1.401090\n",
      "   features  vif_Factor\n",
      "0         2   11.313702\n",
      "1         5   18.490070\n",
      "2         6   16.230960\n",
      "   features  vif_Factor\n",
      "0         2   10.190360\n",
      "1         5   11.195911\n",
      "2         9    2.088057\n",
      "   features  vif_Factor\n",
      "0         2   15.597222\n",
      "1         5   13.612493\n",
      "2        10    1.659148\n",
      "   features  vif_Factor\n",
      "0         2   10.214471\n",
      "1         6    8.978947\n",
      "2         8    1.907467\n",
      "   features  vif_Factor\n",
      "0         2    9.370852\n",
      "1         6    9.045582\n",
      "2         9    1.921825\n",
      "   features  vif_Factor\n",
      "0         2    8.977459\n",
      "1         6    9.052886\n",
      "2        10    1.256981\n",
      "   features  vif_Factor\n",
      "0         2    3.769598\n",
      "1         8    2.165266\n",
      "2         9    2.165494\n",
      "   features  vif_Factor\n",
      "0         2    2.566669\n",
      "1         8    9.783160\n",
      "2        10    6.394245\n",
      "   features  vif_Factor\n",
      "0         2    2.144210\n",
      "1         9    1.900210\n",
      "2        10    1.241841\n",
      "   features  vif_Factor\n",
      "0         3   12.560431\n",
      "1         4   17.689560\n",
      "2         6   16.408867\n",
      "   features  vif_Factor\n",
      "0         3   19.924808\n",
      "1         4   14.918547\n",
      "2         8    2.564059\n",
      "   features  vif_Factor\n",
      "0         3   10.806042\n",
      "1         4   11.943627\n",
      "2         9    2.590925\n",
      "   features  vif_Factor\n",
      "0         3   15.578376\n",
      "1         4   13.597262\n",
      "2        10    1.612085\n",
      "   features  vif_Factor\n",
      "0         3   10.824634\n",
      "1         5   15.835659\n",
      "2         6   18.842250\n",
      "   features  vif_Factor\n",
      "0         3   15.598841\n",
      "1         5   11.344095\n",
      "2         8    2.500958\n",
      "   features  vif_Factor\n",
      "0         3    9.424824\n",
      "1         5    8.420785\n",
      "2         9    2.343183\n",
      "   features  vif_Factor\n",
      "0         3   13.579415\n",
      "1         5   11.524639\n",
      "2        10    1.752665\n",
      "   features  vif_Factor\n",
      "0         3   11.094796\n",
      "1         6   10.009436\n",
      "2         8    1.854597\n",
      "   features  vif_Factor\n",
      "0         3   13.304706\n",
      "1         6   10.444127\n",
      "2         9    2.442470\n",
      "   features  vif_Factor\n",
      "0         3   10.195612\n",
      "1         6    9.997761\n",
      "2        10    1.277844\n",
      "   features  vif_Factor\n",
      "0         3    5.054034\n",
      "1         8    2.360825\n",
      "2         9    2.979757\n",
      "   features  vif_Factor\n",
      "0         3    2.212282\n",
      "1         8    8.199848\n",
      "2        10    5.656409\n",
      "   features  vif_Factor\n",
      "0         3    2.731862\n",
      "1         9    2.354230\n",
      "2        10    1.286669\n",
      "   features  vif_Factor\n",
      "0         4    3.469761\n",
      "1         8    1.466411\n",
      "2         9    2.732184\n",
      "   features  vif_Factor\n",
      "0         4    1.618889\n",
      "1         8    6.874686\n",
      "2        10    5.528214\n",
      "   features  vif_Factor\n",
      "0         4    2.635628\n",
      "1         9    2.602226\n",
      "2        10    1.123111\n",
      "   features  vif_Factor\n",
      "0         5   16.892589\n",
      "1         6   14.841703\n",
      "2         9    2.119811\n",
      "   features  vif_Factor\n",
      "0         5   16.175161\n",
      "1         7   18.071295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2         9    2.341560\n",
      "   features  vif_Factor\n",
      "0         5    2.618325\n",
      "1         8    1.368894\n",
      "2         9    2.122701\n",
      "   features  vif_Factor\n",
      "0         5    1.660699\n",
      "1         8    7.252868\n",
      "2        10    5.838665\n",
      "   features  vif_Factor\n",
      "0         5    2.105080\n",
      "1         9    2.137532\n",
      "2        10    1.109679\n",
      "   features  vif_Factor\n",
      "0         6   16.616834\n",
      "1         7   17.860126\n",
      "2         8    1.802431\n",
      "   features  vif_Factor\n",
      "0         6   16.603295\n",
      "1         7   16.628303\n",
      "2        10    1.258219\n",
      "   features  vif_Factor\n",
      "0         6    2.979838\n",
      "1         8    1.773175\n",
      "2         9    1.947355\n",
      "   features  vif_Factor\n",
      "0         6    1.860466\n",
      "1         8    7.032302\n",
      "2        10    5.272684\n",
      "   features  vif_Factor\n",
      "0         6    2.087162\n",
      "1         9    1.834243\n",
      "2        10    1.252268\n",
      "   features  vif_Factor\n",
      "0         7    4.741224\n",
      "1         8    2.218688\n",
      "2         9    2.882748\n",
      "   features  vif_Factor\n",
      "0         7    2.159442\n",
      "1         8    8.150115\n",
      "2        10    5.693973\n",
      "   features  vif_Factor\n",
      "0         7    2.669336\n",
      "1         9    2.342342\n",
      "2        10    1.259480\n",
      "   features  vif_Factor\n",
      "0         8    4.744397\n",
      "1         9    1.103077\n",
      "2        10    4.783695\n",
      " --------------- 4 ------------\n",
      "   features  vif_Factor\n",
      "0         0   10.378986\n",
      "1         1   10.433345\n",
      "2         2   18.055394\n",
      "3         3   15.575149\n",
      "   features  vif_Factor\n",
      "0         0   10.369662\n",
      "1         1    9.893594\n",
      "2         2   16.036861\n",
      "3         6   11.926559\n",
      "   features  vif_Factor\n",
      "0         0    9.714985\n",
      "1         1   15.363051\n",
      "2         2   10.577282\n",
      "3         8    4.366482\n",
      "   features  vif_Factor\n",
      "0         0   14.501419\n",
      "1         1   19.530722\n",
      "2         2    9.510334\n",
      "3        10    3.302831\n",
      "   features  vif_Factor\n",
      "0         0    6.769004\n",
      "1         1   10.462832\n",
      "2         3   19.569208\n",
      "3         4   10.984254\n",
      "   features  vif_Factor\n",
      "0         0    7.469429\n",
      "1         1   10.960830\n",
      "2         3   16.452497\n",
      "3         5    9.418663\n",
      "   features  vif_Factor\n",
      "0         0    6.758401\n",
      "1         1   10.980164\n",
      "2         3   13.089531\n",
      "3         6   11.284820\n",
      "   features  vif_Factor\n",
      "0         0   12.541176\n",
      "1         1    8.029496\n",
      "2         4   16.938047\n",
      "3         9    5.825288\n",
      "   features  vif_Factor\n",
      "0         0   13.045773\n",
      "1         1    8.047287\n",
      "2         5   11.176555\n",
      "3         9    3.768790\n",
      "   features  vif_Factor\n",
      "0         0    8.140572\n",
      "1         1    9.927207\n",
      "2         6   10.638816\n",
      "3         9    2.382178\n",
      "   features  vif_Factor\n",
      "0         0    7.897501\n",
      "1         2   19.959262\n",
      "2         3   14.678932\n",
      "3         6   11.853508\n",
      "   features  vif_Factor\n",
      "0         0    8.764683\n",
      "1         2   17.792804\n",
      "2         3   11.189753\n",
      "3         8    2.130424\n",
      "   features  vif_Factor\n",
      "0         0    7.983118\n",
      "1         2   17.813441\n",
      "2         3   11.400869\n",
      "3        10    1.291509\n",
      "   features  vif_Factor\n",
      "0         0    8.762252\n",
      "1         2   16.080892\n",
      "2         6    8.979893\n",
      "3         8    2.117212\n",
      "   features  vif_Factor\n",
      "0         0    7.975800\n",
      "1         2   16.192588\n",
      "2         6    9.052899\n",
      "3        10    1.269973\n",
      "   features  vif_Factor\n",
      "0         0    5.360335\n",
      "1         3   15.229191\n",
      "2         4   18.245740\n",
      "3         6   17.861831\n",
      "   features  vif_Factor\n",
      "0         0    5.235944\n",
      "1         3   12.398682\n",
      "2         5   15.954518\n",
      "3         6   19.081992\n",
      "   features  vif_Factor\n",
      "0         0    7.542232\n",
      "1         3   15.609044\n",
      "2         5   15.130137\n",
      "3         8    3.648398\n",
      "   features  vif_Factor\n",
      "0         0    5.174390\n",
      "1         3   15.420363\n",
      "2         5   12.013425\n",
      "3        10    1.754099\n",
      "   features  vif_Factor\n",
      "0         0    6.072551\n",
      "1         3   12.105118\n",
      "2         6   10.748651\n",
      "3         8    2.167072\n",
      "   features  vif_Factor\n",
      "0         0    5.247624\n",
      "1         3   12.099422\n",
      "2         6   10.569292\n",
      "3        10    1.290307\n",
      "   features  vif_Factor\n",
      "0         0    9.617573\n",
      "1         4   18.979083\n",
      "2         9    6.553442\n",
      "3        10    1.355897\n",
      "   features  vif_Factor\n",
      "0         0   14.563920\n",
      "1         5   16.163830\n",
      "2         8    3.072649\n",
      "3         9    4.101580\n",
      "   features  vif_Factor\n",
      "0         0    8.475797\n",
      "1         5   13.359030\n",
      "2         9    3.976011\n",
      "3        10    1.449582\n",
      "   features  vif_Factor\n",
      "0         0    6.771181\n",
      "1         6    8.552628\n",
      "2         8    2.106981\n",
      "3         9    2.369126\n",
      "   features  vif_Factor\n",
      "0         0    5.707559\n",
      "1         6    8.919330\n",
      "2         9    2.367532\n",
      "3        10    1.254274\n",
      "   features  vif_Factor\n",
      "0         1    8.533797\n",
      "1         2   17.203172\n",
      "2         3   17.800266\n",
      "3         5   12.469768\n",
      "   features  vif_Factor\n",
      "0         1    8.555638\n",
      "1         2   13.308903\n",
      "2         3   16.667392\n",
      "3         6   12.774412\n",
      "   features  vif_Factor\n",
      "0         1   14.599753\n",
      "1         2   12.294530\n",
      "2         3   15.481147\n",
      "3        10    2.349642\n",
      "   features  vif_Factor\n",
      "0         1    6.793934\n",
      "1         2   13.883681\n",
      "2         4   15.108410\n",
      "3         9    3.113925\n",
      "   features  vif_Factor\n",
      "0         1   13.007878\n",
      "1         2   13.861224\n",
      "2         4   13.238248\n",
      "3        10    3.006825\n",
      "   features  vif_Factor\n",
      "0         1    6.374434\n",
      "1         2   16.229915\n",
      "2         5   11.203235\n",
      "3         9    2.202530\n",
      "   features  vif_Factor\n",
      "0         1   13.352124\n",
      "1         2   16.567611\n",
      "2         5   16.920244\n",
      "3        10    3.665838\n",
      "   features  vif_Factor\n",
      "0         1    8.348326\n",
      "1         2   11.257731\n",
      "2         6   11.854367\n",
      "3         9    2.130175\n",
      "   features  vif_Factor\n",
      "0         1   14.357894\n",
      "1         2   10.785348\n",
      "2         6   12.100306\n",
      "3        10    2.396192\n",
      "   features  vif_Factor\n",
      "0         1   13.892490\n",
      "1         2    8.836649\n",
      "2         8    4.722085\n",
      "3         9    2.171360\n",
      "   features  vif_Factor\n",
      "0         1   13.879867\n",
      "1         2    7.794754\n",
      "2         8   12.641047\n",
      "3        10    6.405740\n",
      "   features  vif_Factor\n",
      "0         1   11.852647\n",
      "1         2   11.103943\n",
      "2         9    2.096696\n",
      "3        10    2.310594\n",
      "   features  vif_Factor\n",
      "0         1   14.233096\n",
      "1         3   19.399236\n",
      "2         4   14.713715\n",
      "3        10    3.014521\n",
      "   features  vif_Factor\n",
      "0         1   15.329278\n",
      "1         3   16.560178\n",
      "2         5   13.431376\n",
      "3        10    3.541282\n",
      "   features  vif_Factor\n",
      "0         1   15.929442\n",
      "1         3   13.589512\n",
      "2         6   12.108068\n",
      "3        10    2.410827\n",
      "   features  vif_Factor\n",
      "0         1   18.013568\n",
      "1         5   16.567732\n",
      "2         9    3.063194\n",
      "3        10    4.994389\n",
      "   features  vif_Factor\n",
      "0         1   13.010090\n",
      "1         6   11.863998\n",
      "2         9    1.996766\n",
      "3        10    2.344499\n",
      "   features  vif_Factor\n",
      "0         2   13.952525\n",
      "1         3   15.909076\n",
      "2         4   18.791766\n",
      "3         6   17.005604\n",
      "   features  vif_Factor\n",
      "0         2   15.325328\n",
      "1         3   15.888453\n",
      "2         4   16.059168\n",
      "3         9    2.949343\n",
      "   features  vif_Factor\n",
      "0         2   14.174626\n",
      "1         3   18.130165\n",
      "2         4   17.400759\n",
      "3        10    1.697307\n",
      "   features  vif_Factor\n",
      "0         2   15.345924\n",
      "1         3   14.682552\n",
      "2         5   18.502353\n",
      "3         6   18.905990\n",
      "   features  vif_Factor\n",
      "0         2   16.154459\n",
      "1         3   14.940879\n",
      "2         5   11.934989\n",
      "3         9    2.474983\n",
      "   features  vif_Factor\n",
      "0         2   17.591566\n",
      "1         3   15.315751\n",
      "2         5   18.303617\n",
      "3        10    2.015937\n",
      "   features  vif_Factor\n",
      "0         2   13.821128\n",
      "1         3   15.012290\n",
      "2         6   12.050861\n",
      "3         8    1.951600\n",
      "   features  vif_Factor\n",
      "0         2   13.255387\n",
      "1         3   18.819957\n",
      "2         6   12.146232\n",
      "3         9    2.465014\n",
      "   features  vif_Factor\n",
      "0         2   13.141025\n",
      "1         3   14.924133\n",
      "2         6   11.861432\n",
      "3        10    1.278512\n",
      "   features  vif_Factor\n",
      "0         2   11.580428\n",
      "1         3   15.526290\n",
      "2         8    2.398642\n",
      "3         9    3.005872\n",
      "   features  vif_Factor\n",
      "0         2   13.392195\n",
      "1         3   11.543103\n",
      "2         8    9.914314\n",
      "3        10    6.598688\n",
      "   features  vif_Factor\n",
      "0         2   11.405642\n",
      "1         3   14.531528\n",
      "2         9    2.424230\n",
      "3        10    1.287549\n",
      "   features  vif_Factor\n",
      "0         2   18.933965\n",
      "1         4   17.427944\n",
      "2         8    2.663805\n",
      "3         9    2.792933\n",
      "   features  vif_Factor\n",
      "0         2   13.800593\n",
      "1         4   16.963465\n",
      "2         9    2.948565\n",
      "3        10    1.487050\n",
      "   features  vif_Factor\n",
      "0         2   15.743196\n",
      "1         5   15.455902\n",
      "2         9    2.157537\n",
      "3        10    1.714355\n",
      "   features  vif_Factor\n",
      "0         2   11.451514\n",
      "1         6    9.052335\n",
      "2         8    2.166883\n",
      "3         9    2.183194\n",
      "   features  vif_Factor\n",
      "0         2   14.443068\n",
      "1         6   10.469150\n",
      "2         8   11.313671\n",
      "3        10    7.455475\n",
      "   features  vif_Factor\n",
      "0         2    9.407999\n",
      "1         6    9.157694\n",
      "2         9    1.922209\n",
      "3        10    1.257232\n",
      "   features  vif_Factor\n",
      "0         3   15.579984\n",
      "1         4   15.031152\n",
      "2         9    2.602494\n",
      "3        10    1.619284\n",
      "   features  vif_Factor\n",
      "0         3   15.602123\n",
      "1         5   11.712078\n",
      "2         8    8.333212\n",
      "3        10    5.839894\n",
      "   features  vif_Factor\n",
      "0         3   14.957341\n",
      "1         5   11.525619\n",
      "2         9    2.354431\n",
      "3        10    1.761078\n",
      "   features  vif_Factor\n",
      "0         3   18.182221\n",
      "1         6   10.720166\n",
      "2         8    2.423222\n",
      "3         9    3.191338\n",
      "   features  vif_Factor\n",
      "0         3   12.109650\n",
      "1         6   10.183869\n",
      "2         8    8.352487\n",
      "3        10    5.754983\n",
      "   features  vif_Factor\n",
      "0         3   13.670889\n",
      "1         6   10.444655\n",
      "2         9    2.459463\n",
      "3        10    1.286734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   features  vif_Factor\n",
      "0         4    7.416182\n",
      "1         8   13.349880\n",
      "2         9    5.053234\n",
      "3        10   10.224551\n",
      "   features  vif_Factor\n",
      "0         5    5.282486\n",
      "1         8   11.905584\n",
      "2         9    3.508759\n",
      "3        10    9.651132\n",
      "   features  vif_Factor\n",
      "0         6    4.088429\n",
      "1         8    9.293544\n",
      "2         9    2.424045\n",
      "3        10    6.563375\n",
      " --------------- 5 ------------\n",
      "   features  vif_Factor\n",
      "0         0    8.769459\n",
      "1         2   19.959290\n",
      "2         3   15.024638\n",
      "3         6   12.057428\n",
      "4         8    2.167075\n",
      "   features  vif_Factor\n",
      "0         0    7.985039\n",
      "1         2   19.996020\n",
      "2         3   14.941421\n",
      "3         6   11.864287\n",
      "4        10    1.292683\n",
      "   features  vif_Factor\n",
      "0         1   15.539462\n",
      "1         2   17.832769\n",
      "2         3   17.824769\n",
      "3         5   19.481724\n",
      "4        10    3.670885\n",
      "   features  vif_Factor\n",
      "0         1   16.456494\n",
      "1         2   13.575817\n",
      "2         3   17.105496\n",
      "3         6   13.369923\n",
      "4        10    2.459176\n",
      "   features  vif_Factor\n",
      "0         1   17.404546\n",
      "1         2   12.585766\n",
      "2         6   13.447251\n",
      "3         9    2.330089\n",
      "4        10    2.621071\n",
      "   features  vif_Factor\n",
      "0         2   18.496877\n",
      "1         3   17.573566\n",
      "2         5   18.691449\n",
      "3         9    2.475596\n",
      "4        10    2.016437\n",
      "   features  vif_Factor\n",
      "0         2   17.910886\n",
      "1         3   15.017209\n",
      "2         6   13.620031\n",
      "3         8   11.384230\n",
      "4        10    7.457918\n",
      "   features  vif_Factor\n",
      "0         2   13.268186\n",
      "1         3   19.280179\n",
      "2         6   12.150270\n",
      "3         9    2.483262\n",
      "4        10    1.287977\n",
      " --------------- 6 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tzurv\\.conda\\envs\\Scraper\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#   features  vif_Factor\n",
    "#0         0    5.707559\n",
    "#1         6    8.919330\n",
    "#2         9    2.367532\n",
    "#3        10    1.254274\n",
    "\n",
    "#   features  vif_Factor\n",
    "#0         2   13.268186\n",
    "#1         3   19.280179\n",
    "#2         6   12.150270\n",
    "#3         9    2.483262\n",
    "#4        10    1.287977\n",
    "\n",
    "indxs = [x for x in range(11)]\n",
    "for L in range(3,7):\n",
    "    print(f\" --------------- {L} ------------\")\n",
    "    for c in itertools.combinations(indxs,L):\n",
    "        #print(c)\n",
    "        col_idx = np.asarray(c)\n",
    "        partTrainData = XtrainData[:,col_idx]\n",
    "        #print(partTrainData.shape[1])\n",
    "        pdTrain = pd.DataFrame(data=partTrainData, columns=[str(x) for x in range(partTrainData.shape[1])])\n",
    "        #print(pdTrain)\n",
    "\n",
    "        #print(pdTrain.corr())\n",
    "        # https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/pcolor_demo.html\n",
    "        #c = plt.pcolor(pdTrain.corr())\n",
    "        #plt.colorbar(c)\n",
    "\n",
    "\n",
    "        #X=pdTrain.drop([\"11\"], axis=1)\n",
    "        X=pdTrain\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"features\"] = col_idx\n",
    "        vif[\"vif_Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]    \n",
    "        if sum(vif[\"vif_Factor\"]<20) == L:\n",
    "            print(vif)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're done with all the data pre-processing, we can now move the data from numpy arrays to PyTorch's very own data structure - **Torch Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   features  vif_Factor\n",
    "#0         2    9.407999\n",
    "#1         6    9.157694\n",
    "#2         9    1.922209\n",
    "#3        10    1.257232\n",
    "#col_idx = np.array([2, 6, 9, 10])\n",
    "#Predicted\t0.0\t1.0\n",
    "#Actual\t\t\n",
    "#0.0\t22\t24\n",
    "#1.0\t7\t58\n",
    "#21.63\n",
    "\n",
    "#   features  vif_Factor\n",
    "#0         2   14.443068\n",
    "#1         6   10.469150\n",
    "#2         8   11.313671\n",
    "#3        10    7.455475\n",
    "col_idx = np.array([2, 6, 8, 10])\n",
    "\n",
    "\n",
    "#col_idx = np.array([2, 3, 6, 8, 10])\n",
    "partTrainData = XtrainData[:,col_idx]\n",
    "input_seq = torch.from_numpy(partTrainData)\n",
    "target_seq = torch.Tensor(YtrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([111, 4]) 111\n",
      "torch.Size([111])\n"
     ]
    }
   ],
   "source": [
    "print(input_seq.shape, input_seq.shape[0])\n",
    "print(target_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've reached the fun part of this project! We'll be defining the model using the Torch library, and this is where you can add or remove layers, be it fully connected layers, convolutational layers, vanilla RNN layers, LSTM layers, and many more! In this post, we'll be using the basic nn.rnn to demonstrate a simple example of how RNNs can be used.\n",
    "\n",
    "Before we start building the model, let's use a build in feature in PyTorch to check the device we're running on (CPU or GPU). This implementation will not require GPU as the training is really simple. However, as you progress on to large datasets and models with millions of trainable parameters, using the GPU will be very important to speed up your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-27 17:09:36.486974\n"
     ]
    }
   ],
   "source": [
    "dateNow = datetime.datetime.now()\n",
    "print(dateNow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 10, 10, 1\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([111, 4]) torch.Size([111, 1])\n",
      "N=111, D_in=4, H=20, D_out=1\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "dNorm = dataNormalization(partTrainData)\n",
    "normXtrainData = dNorm.normalize(partTrainData)\n",
    "\n",
    "# change numpy representation to float and conver to pytorch tensor\n",
    "x = torch.from_numpy(normXtrainData.astype(np.float32))\n",
    "y = torch.from_numpy(YtrainData.astype(np.float32))\n",
    "# add a Dimension\n",
    "y = y.unsqueeze(1)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = x.shape[0], x.shape[1], 20, 1\n",
    "print(f\"N={N}, D_in={D_in}, H={H}, D_out={D_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logisticregression\n",
    "https://medium.com/biaslyai/pytorch-linear-and-logistic-regression-models-5c5f0da2cb9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim torch.Size([111, 4])\n",
      "Input tensor([-1.0450, -0.9245,  0.5061, -0.4854], device='cuda:0') -> output tensor([0.], device='cuda:0')\n",
      "TwoLayerNet(\n",
      "  (linear1): Linear(in_features=4, out_features=20, bias=True)\n",
      "  (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "Num Model Parameters  541\n",
      "99 21.645668029785156\n",
      "299 21.63776206970215\n",
      "499 21.63776397705078\n",
      "699 21.63776206970215\n",
      "899 21.63776206970215\n",
      "1099 21.63776206970215\n",
      "1299 21.63776206970215\n",
      "1499 21.63776397705078\n",
      "1699 21.63776206970215\n",
      "1899 21.63776206970215\n"
     ]
    }
   ],
   "source": [
    "# source: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-custom-nn-modules\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.linear3 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu1 = self.linear1(x)\n",
    "        h_relu2 = self.linear2(h_relu1)\n",
    "        y_pred  = self.linear3(h_relu2)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "#N, D_in, H, D_out = 64, 10, 10, 1\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "#x = torch.randn(N, D_in)\n",
    "#y = torch.randn(N, D_out)\n",
    "\n",
    "# move to device \n",
    "x = x.to(device)\n",
    "y = y.to(device) \n",
    "\n",
    "print(f\"input dim {x.shape}\")\n",
    "print(f\"Input {x[0,:]} -> output {y[0]}\")\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#print the model\n",
    "print(model)\n",
    "modelParameters = sum([param.nelement() for param in model.parameters()])\n",
    "print('Num Model Parameters ', modelParameters )\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.95)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "\n",
    "##criterion = torch.nn.CrossEntropyLoss()\n",
    "##optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for t in range(2000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 200 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaeb\" ><thead>    <tr>        <th class=\"index_name level0\" >Predicted</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1.0</th>    </tr>    <tr>        <th class=\"index_name level0\" >Actual</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaeblevel0_row0\" class=\"row_heading level0 row0\" >0.0</th>\n",
       "                        <td id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaebrow0_col0\" class=\"data row0 col0\" >22</td>\n",
       "                        <td id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaebrow0_col1\" class=\"data row0 col1\" >24</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaeblevel0_row1\" class=\"row_heading level0 row1\" >1.0</th>\n",
       "                        <td id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaebrow1_col0\" class=\"data row1 col0\" >7</td>\n",
       "                        <td id=\"T_faa98506_e87f_11ea_b98e_00d8614ecaebrow1_col1\" class=\"data row1 col1\" >58</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20e8a471b48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.to('cpu')\n",
    "npActual    = list(torch.squeeze(y).numpy())\n",
    "\n",
    "\n",
    "# evaluate\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "out = out.to('cpu')\n",
    "out = torch.squeeze((out)) \n",
    "npPredicted = out.detach().numpy()\n",
    "npPredicted[npPredicted>0.5]  = 1\n",
    "npPredicted[npPredicted<=0.5] = 0\n",
    "\n",
    "data = {'y_Actual':    npActual,\n",
    "        'y_Predicted': list(npPredicted)\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "#print(df.head())\n",
    "\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "#print (confusion_matrix)\n",
    "confusion_matrix.style\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYnthetic data\n",
    "# Run recognition on new random data\n",
    "XEvalData = npPos\n",
    "YEvalData = npOut\n",
    "for ii in range(10):\n",
    "    noise = np.random.normal(size=(4,4)) / 5\n",
    "    npPos1 = npPos+noise\n",
    "    XEvalData = np.concatenate((XEvalData, npPos1), axis=0)\n",
    "    YEvalData = np.concatenate((YEvalData, npOut ), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 34\n",
      "    y_Actual  y_Predicted\n",
      "0        1.0          1.0\n",
      "1        0.0          1.0\n",
      "2        0.0          1.0\n",
      "3        0.0          1.0\n",
      "4        0.0          1.0\n",
      "5        0.0          0.0\n",
      "6        1.0          1.0\n",
      "7        0.0          1.0\n",
      "8        0.0          1.0\n",
      "9        0.0          1.0\n",
      "10       0.0          1.0\n",
      "11       0.0          1.0\n",
      "12       0.0          1.0\n",
      "13       0.0          1.0\n",
      "14       0.0          1.0\n",
      "15       0.0          1.0\n",
      "16       1.0          1.0\n",
      "17       0.0          1.0\n",
      "18       0.0          1.0\n",
      "19       0.0          1.0\n",
      "20       0.0          1.0\n",
      "21       0.0          1.0\n",
      "22       0.0          1.0\n",
      "23       0.0          1.0\n",
      "24       0.0          1.0\n",
      "25       0.0          1.0\n",
      "26       0.0          1.0\n",
      "27       0.0          1.0\n",
      "28       0.0          1.0\n",
      "29       0.0          1.0\n",
      "30       1.0          1.0\n",
      "31       1.0          0.0\n",
      "32       1.0          1.0\n",
      "33       0.0          1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_210abf8a_e657_11ea_8085_00d8614ecaeb\" ><thead>    <tr>        <th class=\"index_name level0\" >Predicted</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1.0</th>    </tr>    <tr>        <th class=\"index_name level0\" >Actual</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_210abf8a_e657_11ea_8085_00d8614ecaeblevel0_row0\" class=\"row_heading level0 row0\" >0.0</th>\n",
       "                        <td id=\"T_210abf8a_e657_11ea_8085_00d8614ecaebrow0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_210abf8a_e657_11ea_8085_00d8614ecaebrow0_col1\" class=\"data row0 col1\" >27</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_210abf8a_e657_11ea_8085_00d8614ecaeblevel0_row1\" class=\"row_heading level0 row1\" >1.0</th>\n",
       "                        <td id=\"T_210abf8a_e657_11ea_8085_00d8614ecaebrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_210abf8a_e657_11ea_8085_00d8614ecaebrow1_col1\" class=\"data row1 col1\" >5</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1732f0f1588>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "x = torch.from_numpy(dNorm.normalize(XEvalData).astype(np.float32))\n",
    "x = x.to(device)\n",
    "\n",
    "# evaluate\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "    \n",
    "out = out.to('cpu')\n",
    "out = torch.squeeze((out)) \n",
    "npPredicted = out.detach().numpy()\n",
    "npPredicted[npPredicted>0.5]  = 1\n",
    "npPredicted[npPredicted<=0.5] = 0\n",
    "\n",
    "data = {'y_Actual':    list(YEvalData),\n",
    "        'y_Predicted': list(npPredicted)\n",
    "        }\n",
    "print(len(data['y_Actual']), len(data['y_Predicted']))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "print(df)\n",
    "\n",
    "_ = plt.hist(npPredicted[YEvalData>0.5], bins='auto')\n",
    "plt.title(\"Histogram expected 1\")\n",
    "plt.show()\n",
    "\n",
    "_ = plt.hist(npPredicted[YEvalData<0.5], bins='auto')\n",
    "plt.title(\"Histogram with expected 0\")\n",
    "plt.show()\n",
    "\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "#print (confusion_matrix)\n",
    "confusion_matrix.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP Here for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start building our own neural network model, we can define a class that inherits PyTorchs base class (nn.module) for all neural network modules. After doing so, we can start defining some variables and also the layers for our model under the constructor. For this model, well only be using 1 layer of RNN followed by a fully connected layer. The fully connected layer will be in-charge of converting the RNN output to our desired output shape.\n",
    "\n",
    "Well also have to define the forward pass function under forward() as a class method. The order the forward function is sequentially executed, therefore well have to pass the inputs and the zero-initialized hidden state through the RNN layer first, before passing the RNN outputs to the fully-connected layer. Note that we are using the layers that we defined in the constructor.\n",
    "\n",
    "The last method that we have to define is the method that we called earlier to initialize the hidden state - init_hidden(). This basically creates a tensor of zeros in the shape of our hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the model above, we'll have to instantiate the model with the relevant parameters and define our hyperparamters as well. The hyperparameters we're defining below are:\n",
    "\n",
    "- *n_epochs*: Number of Epochs --> This refers to the number of times our model will go through the entire training dataset\n",
    "- *lr*: Learning Rate --> This affects the rate at which our model updates the weights in the cells each time backpropogation is done\n",
    "    - A smaller learning rate means that the model changes the values of the weight with a smaller magnitude\n",
    "    - A larger learning rate means that the weights are updated to a larger extent for each time step\n",
    "\n",
    "Similar to other neural networks, we have to define the optimizer and loss function as well. Well be using CrossEntropyLoss as the final output is basically a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runAllCells:\n",
    "\n",
    "    #Returns the index of a currently selected device.\n",
    "    print(f\"Currently selected device {torch.cuda.current_device()}\")\n",
    "\n",
    "    print(f\"Returns the number of GPUs available {torch.cuda.device_count()}\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def saveModel(testDes, model, epoch, loss):\n",
    "    basePath = \"C:\\\\Users\\\\tzurv\\\\python\\\\GoogleCloud\\\\testOutput\"\n",
    "    dir = os.path.join(basePath, testDes, str(epoch))\n",
    "    #print(dir)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)   \n",
    "    fileName = dir+\"\\\\modelNN.pt\"\n",
    "    print(f\"saving {fileName}\")\n",
    "    torch.save(model, fileName)\n",
    "    \n",
    "    outFile = open(dir+'\\\\loss.txt', 'w')\n",
    "    outFile.write(f\"{loss}\\n\")\n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Instantiate the model with hyperparameters\n",
    "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=200, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 4\n",
    "lr=0.001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=char2int[ignoreChar])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the model\n",
    "print(model)\n",
    "modelParameters = sum([param.nelement() for param in model.parameters()])\n",
    "print('Num Model Parameters ', modelParameters )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin our training! As we only have a few sentences, this training process is very fast. However, as we progress, larger datasets and deeper models mean that the input data is much larger and the number of parameters within the model that we have to compute is much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "totSentences = input_seq.shape[0]\n",
    "batchSize = 2000\n",
    "\n",
    "testDes = \"20200805_\"+str(n_epochs)+\"_\"+str(batchSize)+\"_\"+str(lr)+\"_P\"+str(modelParameters)\n",
    "\n",
    "# Training Run\n",
    "#input_seq = input_seq.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    totLoss = 0\n",
    "    batchNo = 0\n",
    "    for start in range(0, totSentences, batchSize):\n",
    "    \n",
    "        # get batch data\n",
    "        batchNo += 1\n",
    "        batch_input_seq  = input_seq[start:start+batchSize,  :, :]\n",
    "        batch_target_seq = target_seq[start:start+batchSize, :   ]\n",
    "    \n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "\n",
    "        batch_input_seq = batch_input_seq.to(device)\n",
    "        output, hidden = model(batch_input_seq)\n",
    "        output = output.to(device)\n",
    "        batch_target_seq = batch_target_seq.to(device)\n",
    "\n",
    "        loss = criterion(output, batch_target_seq.view(-1).long())\n",
    "        totLoss += loss.item()\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%200 == 0:\n",
    "    #if True:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(totLoss/batchNo))\n",
    "        if epoch%400 == 0:\n",
    "            saveModel(testDes, model, epoch, loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test our model now and see what kind of output we will get. Before that, lets define some helper function to convert our model output back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    character = character.to(device)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    #print(prob)\n",
    "    \n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "    #print(char_ind)\n",
    "\n",
    "    return int2char[char_ind], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, out_len, start=' '):\n",
    "    #print(\"Eval output\")\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "        \n",
    "        #print(ii, f\"!{char}!\")\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is able to come up with the sentence good i am fine  if we feed it with the words good, achieving what we intended for it to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "PATH = \"C:\\\\Users\\\\tzurv\\\\python\\\\GoogleCloud\\\\testOutput\\\\\" +testDes + \"\\\\\"\n",
    "os.chdir(PATH)\n",
    "\n",
    "files = glob.glob(\"*\")\n",
    "prvPredictedOut = \"\"\n",
    "for indx in sorted(files, key = int):\n",
    "    modelFileName = PATH + \"\\\\\" + indx + \"\\\\modelNN.pt\"\n",
    "    \n",
    "    # Model class must be defined somewhere\n",
    "    model = torch.load(modelFileName)\n",
    "    model.eval()\n",
    "    \n",
    "    predictedOut = sample(model, 50, ' ')\n",
    "    if not predictedOut == prvPredictedOut:\n",
    "        # get loss\n",
    "        lossFile = open(PATH + \"\\\\\" + indx + \"\\\\loss.txt\" , 'rt')\n",
    "        loss = lossFile.readline().rstrip()\n",
    "        lossFile.close()\n",
    "        \n",
    "        # print information\n",
    "        print(f\"{indx},  loss is {loss}\")\n",
    "        print(f\"!{predictedOut}!\")\n",
    "        \n",
    "        # store last prediction\n",
    "        prvPredictedOut = predictedOut\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "PATH = \"C:\\\\Users\\\\tzurv\\\\python\\\\GoogleCloud\\\\testOutput\\\\\" +testDes + \"\\\\\"\n",
    "os.chdir(PATH)\n",
    "\n",
    "files = glob.glob(\"*\")\n",
    "prvPredictedOut = \"\"\n",
    "for indx in sorted(files, key = int):\n",
    "    modelFileName = PATH + \"\\\\\" + indx + \"\\\\modelNN.pt\"\n",
    "    \n",
    "    # Model class must be defined somewhere\n",
    "    model = torch.load(modelFileName)\n",
    "    model.eval()\n",
    "    \n",
    "    predictedOut = sample(model, 50, ' , ')\n",
    "    if not predictedOut == prvPredictedOut:\n",
    "        # get loss\n",
    "        lossFile = open(PATH + \"\\\\\" + indx + \"\\\\loss.txt\" , 'rt')\n",
    "        loss = lossFile.readline().rstrip()\n",
    "        lossFile.close()\n",
    "        \n",
    "        # print information\n",
    "        print(f\"{indx},  loss is {loss}\")\n",
    "        print(f\"!{predictedOut}!\")\n",
    "        \n",
    "        # store last prediction\n",
    "        prvPredictedOut = predictedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(model, 50, ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scraper",
   "language": "python",
   "name": "scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
